[INFO|_client|L1773] 2024-06-09 13:51:18: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-319a-4afb-b90c-25768c74cb3b/result/markdown "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 13:51:18: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:51:18: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:18: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 13:51:18: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:18: close.started
[DEBUG|_trace|L85] 2024-06-09 13:51:18: close.complete
[DEBUG|proactor_events|L633] 2024-06-09 13:51:18: Using proactor: IocpProactor
[DEBUG|_config|L80] 2024-06-09 13:51:18: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 13:51:18: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 13:51:19: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 13:51:19: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000015310D9ACD0>
[DEBUG|_trace|L85] 2024-06-09 13:51:19: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000015310DA5760> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 13:51:19: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000015324E15E10>
[DEBUG|_trace|L85] 2024-06-09 13:51:19: send_request_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:51:19: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:19: send_request_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:51:20: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:20: receive_response_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:51:21: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 11:51:20 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'4055abcb-c31f-42c9-bfc1-959426a24937'), (b'x-correlation-id', b'17755c20-786c-484c-ad19-4849aa62e0a3'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 13:51:21: HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 13:51:21: receive_response_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:51:21: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:21: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 13:51:21: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:21: close.started
[DEBUG|_trace|L85] 2024-06-09 13:51:21: close.complete
[DEBUG|_config|L80] 2024-06-09 13:51:22: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 13:51:22: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 13:51:22: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 13:51:23: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000015310B647D0>
[DEBUG|_trace|L85] 2024-06-09 13:51:23: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000015310DA6690> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 13:51:23: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000015310B66790>
[DEBUG|_trace|L85] 2024-06-09 13:51:23: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:51:23: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:23: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:51:23: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:23: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:51:23: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 11:51:22 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'47a9387d-f283-4ac4-b2a0-a91f95a979bb'), (b'x-correlation-id', b'64c70804-eef4-42ea-b201-0a73910f4c0a'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 13:51:23: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-191f-453b-8842-5ebf6b6ee714 "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 13:51:23: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:51:23: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:23: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 13:51:23: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:23: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:51:23: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:23: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:51:23: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:23: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:51:23: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 11:51:23 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'1464'), (b'Connection', b'keep-alive'), (b'x-session-id', b'c1d3a654-cb85-4fb1-a21f-7776c8770462'), (b'x-correlation-id', b'411a487e-a2c9-415e-bb31-4a64f5579751'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 13:51:23: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-191f-453b-8842-5ebf6b6ee714/result/markdown "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 13:51:23: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:51:23: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:23: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 13:51:23: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:23: close.started
[DEBUG|_trace|L85] 2024-06-09 13:51:23: close.complete
[DEBUG|proactor_events|L633] 2024-06-09 13:51:23: Using proactor: IocpProactor
[DEBUG|_config|L80] 2024-06-09 13:51:23: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 13:51:23: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 13:51:24: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 13:51:24: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000015324E212D0>
[DEBUG|_trace|L85] 2024-06-09 13:51:24: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000015310DA6DE0> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 13:51:24: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x00000152FB1E4390>
[DEBUG|_trace|L85] 2024-06-09 13:51:24: send_request_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:51:24: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:24: send_request_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:51:25: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:25: receive_response_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:51:27: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 11:51:26 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'd3e20dd8-c075-4fc3-8e68-6792fcc0f8f7'), (b'x-correlation-id', b'4702f040-31be-489f-8bb0-9408e9024be8'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 13:51:27: HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 13:51:27: receive_response_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:51:27: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:27: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 13:51:27: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:27: close.started
[DEBUG|_trace|L85] 2024-06-09 13:51:27: close.complete
[DEBUG|_config|L80] 2024-06-09 13:51:28: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 13:51:28: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 13:51:28: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 13:51:28: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000015324E22710>
[DEBUG|_trace|L85] 2024-06-09 13:51:28: start_tls.started ssl_context=<ssl.SSLContext object at 0x00000152FDDC45F0> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 13:51:28: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000015310DC4610>
[DEBUG|_trace|L85] 2024-06-09 13:51:28: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:51:28: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:28: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:51:28: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:28: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:51:29: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 11:51:28 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'eac01e9a-5670-4e75-9cc6-1227d31f4931'), (b'x-correlation-id', b'da792e4b-e2ca-43bb-ac77-93e1b2b5db50'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 13:51:29: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-6c81-4bb1-ae3c-62ad1ed1589c "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 13:51:29: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:51:29: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:29: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 13:51:29: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:29: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:51:29: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:29: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:51:29: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:29: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:51:29: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 11:51:29 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'886414'), (b'Connection', b'keep-alive'), (b'x-session-id', b'17ea508c-348b-4e7a-981f-bad678abd73c'), (b'x-correlation-id', b'8f29b060-c083-4c13-9eb8-7cf816dba9df'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 13:51:29: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-6c81-4bb1-ae3c-62ad1ed1589c/result/markdown "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 13:51:29: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:51:30: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:30: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 13:51:30: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:30: close.started
[DEBUG|_trace|L85] 2024-06-09 13:51:30: close.complete
[INFO|parsers|L84] 2024-06-09 13:51:32: Parsed num of docs -> 9
[INFO|etl|L255] 2024-06-09 13:51:32: Configuration of TextPreprocess for task : classification founded
[DEBUG|etl|L259] 2024-06-09 13:51:32: Trying to preprocess texts --> del_stopwords : {'apply': True, 'lang': 'Spanish'}
[DEBUG|base|L311] 2024-06-09 14:05:47: > [SimpleDirectoryReader] Total files added: 9
[INFO|SentenceTransformer|L113] 2024-06-09 14:05:47: Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
[DEBUG|connectionpool|L546] 2024-06-09 14:05:47: https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/modules.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 14:05:47: https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/config_sentence_transformers.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 14:05:47: https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/README.md HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 14:05:47: https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/modules.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 14:05:47: https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/sentence_bert_config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 14:05:48: https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 14:05:49: https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 14:05:51: https://huggingface.co:443 "GET /api/models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/revision/main HTTP/1.1" 200 5391
[INFO|SentenceTransformer|L219] 2024-06-09 14:05:51: Use pytorch device_name: cpu
[INFO|SentenceTransformer|L113] 2024-06-09 14:05:51: Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
[DEBUG|connectionpool|L546] 2024-06-09 14:05:51: https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/modules.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 14:05:51: https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/config_sentence_transformers.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 14:05:51: https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/README.md HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 14:05:51: https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/modules.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 14:05:52: https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/sentence_bert_config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 14:05:52: https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 14:05:53: https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 14:05:55: https://huggingface.co:443 "GET /api/models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/revision/main HTTP/1.1" 200 5391
[INFO|SentenceTransformer|L219] 2024-06-09 14:05:55: Use pytorch device_name: cpu
[DEBUG|connectionpool|L546] 2024-06-09 14:05:56: https://huggingface.co:443 "HEAD /gpt2/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 14:05:56: https://huggingface.co:443 "HEAD /meta-llama/Meta-Llama-3-8B/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 14:05:57: https://huggingface.co:443 "HEAD /microsoft/deberta-base/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 14:05:57: https://huggingface.co:443 "HEAD /PlanTL-GOB-ES/roberta-base-bne/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 14:05:57: https://huggingface.co:443 "HEAD /meta-llama/Meta-Llama-3-8B/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 14:05:58: https://huggingface.co:443 "HEAD /gpt2/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 14:05:58: https://huggingface.co:443 "HEAD /meta-llama/Meta-Llama-3-8B/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 14:05:59: https://huggingface.co:443 "HEAD /microsoft/deberta-base/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 14:05:59: https://huggingface.co:443 "HEAD /PlanTL-GOB-ES/roberta-base-bne/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 14:05:59: https://huggingface.co:443 "HEAD /meta-llama/Meta-Llama-3-8B/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
[DEBUG|_config|L80] 2024-06-09 14:06:00: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 14:06:00: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_config|L80] 2024-06-09 14:06:00: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 14:06:00: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|proactor_events|L633] 2024-06-09 14:06:01: Using proactor: IocpProactor
[DEBUG|_config|L80] 2024-06-09 14:06:01: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 14:06:01: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 14:06:01: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 14:06:02: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000020F4FAAA3D0>
[DEBUG|_trace|L85] 2024-06-09 14:06:02: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000020F4FD257F0> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 14:06:02: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000020F64BF9810>
[DEBUG|_trace|L85] 2024-06-09 14:06:02: send_request_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 14:06:02: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:02: send_request_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 14:06:02: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:02: receive_response_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 14:06:03: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 12:06:03 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'cc7b27b1-e9ed-458b-abd5-15fb4ea4d530'), (b'x-correlation-id', b'1e15d2ff-4443-47be-8ca5-396d742f76b2'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 14:06:03: HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 14:06:03: receive_response_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 14:06:03: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:03: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 14:06:03: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:03: close.started
[DEBUG|_trace|L85] 2024-06-09 14:06:03: close.complete
[DEBUG|_config|L80] 2024-06-09 14:06:04: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 14:06:04: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 14:06:05: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 14:06:05: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000020F6553B7D0>
[DEBUG|_trace|L85] 2024-06-09 14:06:05: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000020F4FD26600> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 14:06:05: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000020F798C0990>
[DEBUG|_trace|L85] 2024-06-09 14:06:05: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:05: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:05: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:05: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:05: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:05: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 12:06:05 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'de50e482-d4e8-4950-8f55-5abb9fbf5827'), (b'x-correlation-id', b'149b5b46-33cc-4891-8f68-8512c6b99d09'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 14:06:05: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-de4c-4c8e-b1c8-0d7e2e37f197 "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 14:06:05: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:05: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:05: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 14:06:05: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:05: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:05: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:05: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:05: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:05: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:06: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 12:06:05 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'6020'), (b'Connection', b'keep-alive'), (b'x-session-id', b'a0499ca8-bca0-4bdc-a4d2-3a1d6b5632f6'), (b'x-correlation-id', b'86e88562-0d77-47cd-b658-483930c8ab99'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 14:06:06: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-de4c-4c8e-b1c8-0d7e2e37f197/result/markdown "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 14:06:06: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:06: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:06: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 14:06:06: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:06: close.started
[DEBUG|_trace|L85] 2024-06-09 14:06:06: close.complete
[DEBUG|proactor_events|L633] 2024-06-09 14:06:06: Using proactor: IocpProactor
[DEBUG|_config|L80] 2024-06-09 14:06:06: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 14:06:06: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 14:06:06: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 14:06:06: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000020F50943150>
[DEBUG|_trace|L85] 2024-06-09 14:06:06: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000020F4FD264E0> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 14:06:06: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000020F35FE5110>
[DEBUG|_trace|L85] 2024-06-09 14:06:06: send_request_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 14:06:06: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:06: send_request_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 14:06:07: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:07: receive_response_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 14:06:09: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 12:06:08 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'8a11ef80-19db-4ac4-9ebf-1594538011dd'), (b'x-correlation-id', b'99d84681-da58-4400-9344-6fdb57149971'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 14:06:09: HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 14:06:09: receive_response_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 14:06:09: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:09: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 14:06:09: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:09: close.started
[DEBUG|_trace|L85] 2024-06-09 14:06:09: close.complete
[DEBUG|_config|L80] 2024-06-09 14:06:10: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 14:06:10: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 14:06:10: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 14:06:10: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000020F4FAE6090>
[DEBUG|_trace|L85] 2024-06-09 14:06:10: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000020F4FD255B0> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 14:06:10: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000020F798C07D0>
[DEBUG|_trace|L85] 2024-06-09 14:06:10: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:10: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:10: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:10: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:10: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 12:06:10 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'271eee3b-e6dc-4a23-a01e-e3ddaa5bd998'), (b'x-correlation-id', b'cdc496f4-2795-46fe-8ab0-f042b1e25adf'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 14:06:11: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-9b74-4cb4-b51d-0662ded0844e "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 14:06:11: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:11: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:11: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 14:06:11: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:11: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:11: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:11: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:11: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:11: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 12:06:11 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'4083'), (b'Connection', b'keep-alive'), (b'x-session-id', b'd84a9031-179e-4d36-91d5-2bc00f707d1f'), (b'x-correlation-id', b'97f02c19-409b-4449-b610-6fc955e36469'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 14:06:11: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-9b74-4cb4-b51d-0662ded0844e/result/markdown "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 14:06:11: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:11: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:11: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 14:06:11: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:11: close.started
[DEBUG|_trace|L85] 2024-06-09 14:06:11: close.complete
[DEBUG|proactor_events|L633] 2024-06-09 14:06:11: Using proactor: IocpProactor
[DEBUG|_config|L80] 2024-06-09 14:06:11: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 14:06:11: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 14:06:11: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 14:06:12: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000020F79763CD0>
[DEBUG|_trace|L85] 2024-06-09 14:06:12: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000020F4FD26450> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 14:06:12: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000020F6553BA50>
[DEBUG|_trace|L85] 2024-06-09 14:06:12: send_request_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 14:06:12: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:12: send_request_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 14:06:12: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:12: receive_response_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 14:06:13: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 12:06:13 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'3deaf05f-531a-4648-b48f-b29105333cf4'), (b'x-correlation-id', b'a6a87322-8ad4-4c45-b32f-82e5aad549e3'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 14:06:13: HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 14:06:13: receive_response_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 14:06:13: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:13: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 14:06:13: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:13: close.started
[DEBUG|_trace|L85] 2024-06-09 14:06:13: close.complete
[DEBUG|_config|L80] 2024-06-09 14:06:14: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 14:06:14: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 14:06:15: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 14:06:15: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000020F79763550>
[DEBUG|_trace|L85] 2024-06-09 14:06:15: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000020F4FD263C0> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 14:06:15: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000020F79761ED0>
[DEBUG|_trace|L85] 2024-06-09 14:06:15: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:15: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:15: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:15: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:15: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:15: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 12:06:15 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'9a260e0f-0568-4f3d-85df-12a617805d68'), (b'x-correlation-id', b'0e1a059c-f3e4-479c-adee-ca50c6581bcd'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 14:06:15: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-e76f-42ee-a841-f3a0a9361f88 "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 14:06:15: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:15: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:15: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 14:06:15: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:15: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:15: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:15: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:15: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:15: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:15: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 12:06:15 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'4083'), (b'Connection', b'keep-alive'), (b'x-session-id', b'be010d26-dea4-4957-ab2b-3e9929f1037f'), (b'x-correlation-id', b'c7d55a35-2cc0-4a55-a06f-fa444cef4d42'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 14:06:15: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-e76f-42ee-a841-f3a0a9361f88/result/markdown "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 14:06:15: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:15: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:15: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 14:06:15: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:15: close.started
[DEBUG|_trace|L85] 2024-06-09 14:06:15: close.complete
[DEBUG|proactor_events|L633] 2024-06-09 14:06:15: Using proactor: IocpProactor
[DEBUG|_config|L80] 2024-06-09 14:06:15: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 14:06:15: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 14:06:16: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 14:06:16: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000020F798CC550>
[DEBUG|_trace|L85] 2024-06-09 14:06:16: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000020F4FD257F0> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 14:06:16: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000020F79762A10>
[DEBUG|_trace|L85] 2024-06-09 14:06:16: send_request_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 14:06:16: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:16: send_request_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 14:06:17: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:17: receive_response_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 14:06:19: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 12:06:18 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'1d6e8071-c107-4ff3-bae4-83ee339a12c9'), (b'x-correlation-id', b'a4888a56-507a-4592-81c2-827bede051d3'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 14:06:19: HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 14:06:19: receive_response_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 14:06:19: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:19: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 14:06:19: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:19: close.started
[DEBUG|_trace|L85] 2024-06-09 14:06:19: close.complete
[DEBUG|_config|L80] 2024-06-09 14:06:20: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 14:06:20: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 14:06:20: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 14:06:20: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000020F798CE810>
[DEBUG|_trace|L85] 2024-06-09 14:06:20: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000020F4FD268D0> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 14:06:20: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000020F798CE650>
[DEBUG|_trace|L85] 2024-06-09 14:06:20: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:20: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:20: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:20: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:20: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:21: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 12:06:20 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'0e9c1207-7976-45a0-99f3-1fe2574449eb'), (b'x-correlation-id', b'f4640d39-595c-4573-8512-38aad038aa7e'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 14:06:21: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-1672-4b09-aa6d-3a30d47576bc "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 14:06:21: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:21: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:21: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 14:06:21: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:21: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:21: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:21: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:21: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:21: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:21: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 12:06:21 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'233734'), (b'Connection', b'keep-alive'), (b'x-session-id', b'fee52f7c-5329-4eaf-9bca-0a8b85f30f3b'), (b'x-correlation-id', b'9c316d01-baaa-4fcb-a4b5-f73039ff9a55'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 14:06:21: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-1672-4b09-aa6d-3a30d47576bc/result/markdown "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 14:06:21: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:22: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:22: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 14:06:22: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:22: close.started
[DEBUG|_trace|L85] 2024-06-09 14:06:22: close.complete
[DEBUG|proactor_events|L633] 2024-06-09 14:06:22: Using proactor: IocpProactor
[DEBUG|_config|L80] 2024-06-09 14:06:22: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 14:06:22: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 14:06:22: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 14:06:22: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000020F4FAE6E50>
[DEBUG|_trace|L85] 2024-06-09 14:06:22: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000020F4FD27650> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 14:06:22: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000020F5083A510>
[DEBUG|_trace|L85] 2024-06-09 14:06:22: send_request_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 14:06:22: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:22: send_request_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 14:06:23: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:23: receive_response_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 14:06:24: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 12:06:24 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'd096bbf0-3d56-4105-abdd-843529573005'), (b'x-correlation-id', b'3090afa6-3413-43db-a33d-91bf353be483'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 14:06:24: HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 14:06:24: receive_response_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 14:06:24: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:24: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 14:06:24: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:24: close.started
[DEBUG|_trace|L85] 2024-06-09 14:06:24: close.complete
[DEBUG|_config|L80] 2024-06-09 14:06:25: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 14:06:25: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 14:06:26: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 14:06:26: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000020F4FAA86D0>
[DEBUG|_trace|L85] 2024-06-09 14:06:26: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000020F4FD26690> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 14:06:26: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000020F798C0E10>
[DEBUG|_trace|L85] 2024-06-09 14:06:26: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:26: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:26: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:26: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:26: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:26: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 12:06:26 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'49b040c2-2ecd-4a71-ba55-851aa571d3ae'), (b'x-correlation-id', b'f755af5d-fbad-4b38-b4f7-f423beac9e1a'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 14:06:26: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-0d08-40eb-bb3b-a4a27740a546 "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 14:06:26: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:26: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:26: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 14:06:26: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:26: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:26: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:26: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:26: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:26: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:27: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 12:06:27 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'8463'), (b'Connection', b'keep-alive'), (b'x-session-id', b'5b12a4b7-06b2-4dac-9a4d-e7deff65feb4'), (b'x-correlation-id', b'92a42a5f-1619-4798-8b12-4e10f5d208fd'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 14:06:27: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-0d08-40eb-bb3b-a4a27740a546/result/markdown "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 14:06:27: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:27: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:27: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 14:06:27: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:27: close.started
[DEBUG|_trace|L85] 2024-06-09 14:06:27: close.complete
[DEBUG|proactor_events|L633] 2024-06-09 14:06:27: Using proactor: IocpProactor
[DEBUG|_config|L80] 2024-06-09 14:06:27: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 14:06:27: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 14:06:28: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 14:06:28: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000020F79761A90>
[DEBUG|_trace|L85] 2024-06-09 14:06:28: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000020F4FD27020> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 14:06:28: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000020F798CF8D0>
[DEBUG|_trace|L85] 2024-06-09 14:06:28: send_request_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 14:06:28: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:28: send_request_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 14:06:29: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:29: receive_response_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 14:06:30: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 12:06:30 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'fd5472ff-98e7-411f-9ca0-d8b8126af7e3'), (b'x-correlation-id', b'570015bb-9198-42d1-89a4-23442ad8efbe'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 14:06:30: HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 14:06:30: receive_response_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 14:06:30: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:30: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 14:06:30: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:30: close.started
[DEBUG|_trace|L85] 2024-06-09 14:06:30: close.complete
[DEBUG|_config|L80] 2024-06-09 14:06:31: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 14:06:31: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 14:06:33: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 14:06:33: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000020F797632D0>
[DEBUG|_trace|L85] 2024-06-09 14:06:33: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000020F4FD257F0> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 14:06:33: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000020F79761590>
[DEBUG|_trace|L85] 2024-06-09 14:06:33: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:33: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:33: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:33: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:33: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:33: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 12:06:33 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'326770cb-1903-4b4c-b64e-f460352e9b81'), (b'x-correlation-id', b'74681bb1-1414-408a-9df5-e9c4c78a33c1'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 14:06:33: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-9ce8-4f26-902d-bbf303106ad8 "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 14:06:33: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:33: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:33: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 14:06:33: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:33: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:33: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:33: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:33: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:33: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:34: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 12:06:33 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'12669'), (b'Connection', b'keep-alive'), (b'x-session-id', b'c25eef13-a5db-4a16-b28e-bacee1d9dc88'), (b'x-correlation-id', b'74df78d4-dfde-4947-ad2b-7bc81fd8c391'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 14:06:34: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-9ce8-4f26-902d-bbf303106ad8/result/markdown "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 14:06:34: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:34: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:34: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 14:06:34: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:34: close.started
[DEBUG|_trace|L85] 2024-06-09 14:06:34: close.complete
[DEBUG|proactor_events|L633] 2024-06-09 14:06:34: Using proactor: IocpProactor
[DEBUG|_config|L80] 2024-06-09 14:06:34: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 14:06:34: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 14:06:34: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 14:06:34: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000020F79B0C550>
[DEBUG|_trace|L85] 2024-06-09 14:06:34: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000020F4FD27E30> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 14:06:34: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000020F4FAA9C10>
[DEBUG|_trace|L85] 2024-06-09 14:06:34: send_request_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 14:06:35: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:35: send_request_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 14:06:35: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:35: receive_response_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 14:06:36: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 12:06:36 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'0a56b851-ac12-4b83-b841-b25d1a357d32'), (b'x-correlation-id', b'b5cf0b94-63e8-44d1-a7b3-9ebc18eb5fe5'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 14:06:36: HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 14:06:36: receive_response_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 14:06:36: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:36: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 14:06:36: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:36: close.started
[DEBUG|_trace|L85] 2024-06-09 14:06:36: close.complete
[DEBUG|_config|L80] 2024-06-09 14:06:37: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 14:06:37: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 14:06:38: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 14:06:38: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000020F79B0FB50>
[DEBUG|_trace|L85] 2024-06-09 14:06:38: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000020F4FD27EC0> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 14:06:38: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000020F79B0FDD0>
[DEBUG|_trace|L85] 2024-06-09 14:06:38: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:38: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:38: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:38: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:38: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:38: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 12:06:38 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'1cd47807-f6c6-4921-b547-261611ed0e80'), (b'x-correlation-id', b'85a9a151-9231-4e1b-bd40-f35beec26088'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 14:06:38: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-2785-4fff-8b64-f975fd8f73f5 "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 14:06:38: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:38: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:38: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 14:06:38: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:38: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:38: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:38: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:38: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:38: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:38: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 12:06:38 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'1341'), (b'Connection', b'keep-alive'), (b'x-session-id', b'f7db0106-adc0-40c7-9a9f-51bba236f745'), (b'x-correlation-id', b'280a20de-3909-4280-b05a-93dbbf031b47'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 14:06:38: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-2785-4fff-8b64-f975fd8f73f5/result/markdown "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 14:06:38: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:38: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:38: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 14:06:38: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:38: close.started
[DEBUG|_trace|L85] 2024-06-09 14:06:38: close.complete
[DEBUG|proactor_events|L633] 2024-06-09 14:06:38: Using proactor: IocpProactor
[DEBUG|_config|L80] 2024-06-09 14:06:38: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 14:06:38: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 14:06:39: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 14:06:39: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000020F79763C90>
[DEBUG|_trace|L85] 2024-06-09 14:06:39: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000020F4FD267B0> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 14:06:39: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000020F79B0E050>
[DEBUG|_trace|L85] 2024-06-09 14:06:39: send_request_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 14:06:39: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:39: send_request_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 14:06:40: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:40: receive_response_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 14:06:41: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 12:06:41 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'a190fed0-ebc7-4674-b4af-26aaa0a7553b'), (b'x-correlation-id', b'e187482e-c090-4649-ac81-9a5753b93cf7'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 14:06:41: HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 14:06:41: receive_response_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 14:06:41: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:41: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 14:06:41: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:41: close.started
[DEBUG|_trace|L85] 2024-06-09 14:06:41: close.complete
[DEBUG|_config|L80] 2024-06-09 14:06:42: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 14:06:42: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 14:06:43: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 14:06:43: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000020F5083A510>
[DEBUG|_trace|L85] 2024-06-09 14:06:43: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000020F4FD27650> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 14:06:43: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000020F4FD35010>
[DEBUG|_trace|L85] 2024-06-09 14:06:43: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:43: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:43: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:43: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:43: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:43: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 12:06:43 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'c2ac97f1-dffc-4067-8fb0-9e8ace5b044c'), (b'x-correlation-id', b'14d525bf-57fa-4330-841d-96b5fae8dd44'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 14:06:43: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-6dc5-4044-bafb-78726b11a1ee "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 14:06:43: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:43: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:43: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 14:06:43: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:43: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:43: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:43: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:43: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:43: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:44: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 12:06:44 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'1464'), (b'Connection', b'keep-alive'), (b'x-session-id', b'424ae6c8-d487-477b-a889-edc4ba873c3f'), (b'x-correlation-id', b'93d7f150-554c-41d0-b064-1359c6f432f6'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 14:06:44: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-6dc5-4044-bafb-78726b11a1ee/result/markdown "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 14:06:44: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:44: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:44: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 14:06:44: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:44: close.started
[DEBUG|_trace|L85] 2024-06-09 14:06:44: close.complete
[DEBUG|proactor_events|L633] 2024-06-09 14:06:44: Using proactor: IocpProactor
[DEBUG|_config|L80] 2024-06-09 14:06:44: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 14:06:44: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 14:06:45: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 14:06:45: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000020F4FAA8E90>
[DEBUG|_trace|L85] 2024-06-09 14:06:45: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000020F4FD27890> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 14:06:45: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000020F79B0E650>
[DEBUG|_trace|L85] 2024-06-09 14:06:45: send_request_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 14:06:45: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:45: send_request_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 14:06:46: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:46: receive_response_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 14:06:48: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 12:06:48 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'548c916b-7896-4e69-986b-fc053a5dd5aa'), (b'x-correlation-id', b'ffde81f6-5c67-4e80-89ae-d4dab98a4f0c'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 14:06:48: HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 14:06:48: receive_response_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 14:06:48: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:48: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 14:06:48: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:48: close.started
[DEBUG|_trace|L85] 2024-06-09 14:06:48: close.complete
[DEBUG|_config|L80] 2024-06-09 14:06:49: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 14:06:49: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 14:06:50: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 14:06:50: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000020F4FAA9510>
[DEBUG|_trace|L85] 2024-06-09 14:06:50: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000020F55224680> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 14:06:50: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000020F798CC990>
[DEBUG|_trace|L85] 2024-06-09 14:06:50: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:50: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:50: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:50: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:50: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:51: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 12:06:50 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'ef43a32b-f67e-4751-9f60-0f88b6df27ac'), (b'x-correlation-id', b'661539be-5650-4ec3-86b3-f166c7ac4b5b'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 14:06:51: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-25a0-4cc1-868d-5f6981ccfe5f "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 14:06:51: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:51: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:51: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 14:06:51: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:51: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:51: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:51: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:51: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:51: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:51: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 12:06:51 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'886414'), (b'Connection', b'keep-alive'), (b'x-session-id', b'b2a37bf1-8004-40b0-8d5f-957e9309938c'), (b'x-correlation-id', b'32e7fb21-9a74-46d5-9c43-e734bd797e0b'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 14:06:51: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-25a0-4cc1-868d-5f6981ccfe5f/result/markdown "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 14:06:51: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:06:52: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:52: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 14:06:52: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 14:06:52: close.started
[DEBUG|_trace|L85] 2024-06-09 14:06:52: close.complete
[INFO|parsers|L84] 2024-06-09 14:06:55: Parsed num of docs -> 9
[INFO|etl|L255] 2024-06-09 14:06:55: Configuration of TextPreprocess for task : classification founded
[DEBUG|etl|L259] 2024-06-09 14:06:55: Trying to preprocess texts --> del_stopwords : {'apply': True, 'lang': 'Spanish'}
[DEBUG|etl|L259] 2024-06-09 14:06:55: Trying to preprocess texts --> del_urls : {'apply': True}
[DEBUG|etl|L259] 2024-06-09 14:06:55: Trying to preprocess texts --> del_html : {'apply': True}
[DEBUG|etl|L259] 2024-06-09 14:06:55: Trying to preprocess texts --> del_emojis : {'apply': True}
[DEBUG|etl|L259] 2024-06-09 14:06:55: Trying to preprocess texts --> del_special : {'apply': True}
[DEBUG|etl|L259] 2024-06-09 14:06:55: Trying to preprocess texts --> del_digits : {'apply': True}
[DEBUG|etl|L259] 2024-06-09 14:06:55: Trying to preprocess texts --> del_chinese_japanese : {'apply': True}
[DEBUG|etl|L259] 2024-06-09 14:06:55: Trying to preprocess texts --> del_extra_spaces : {'apply': True}
[DEBUG|etl|L259] 2024-06-09 14:06:55: Trying to preprocess texts --> get_lower : {'apply': True}
[DEBUG|etl|L259] 2024-06-09 14:06:55: Trying to preprocess texts --> get_alfanumeric : {'apply': True}
[DEBUG|etl|L259] 2024-06-09 14:06:55: Trying to preprocess texts --> stem : {'apply': True}
[DEBUG|etl|L259] 2024-06-09 14:06:56: Trying to preprocess texts --> lemmatize : {'apply': True}
[DEBUG|etl|L259] 2024-06-09 14:06:56: Trying to preprocess texts --> custom_del : {'apply': True, 'text_field_name': 'str', 'delete': True, 'plot': True, 'storage_path': 'C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\data\\figures\\text'}
[DEBUG|etl|L259] 2024-06-09 14:06:56: Trying to preprocess texts --> bow : {'apply': True, 'storage_path': 'C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\data\\figures\\text\\bow'}
[DEBUG|etl|L259] 2024-06-09 14:06:56: Trying to preprocess texts --> bow_tf_idf : {'apply': True, 'storage_path': 'C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\data\\figures\\text\\bow'}
[INFO|nlp|L328] 2024-06-09 14:06:56: Transformando en 'Document' los textos BOE preprocesados
[DEBUG|base|L311] 2024-06-09 14:12:30: > [SimpleDirectoryReader] Total files added: 9
[INFO|SentenceTransformer|L113] 2024-06-09 14:12:30: Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
[DEBUG|connectionpool|L546] 2024-06-09 14:12:30: https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/modules.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 14:12:30: https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/config_sentence_transformers.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 14:12:30: https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/README.md HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 14:12:30: https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/modules.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 14:12:31: https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/sentence_bert_config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 14:12:31: https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 14:12:32: https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 14:12:33: https://huggingface.co:443 "GET /api/models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/revision/main HTTP/1.1" 200 5391
[INFO|SentenceTransformer|L219] 2024-06-09 14:12:33: Use pytorch device_name: cpu
[INFO|SentenceTransformer|L113] 2024-06-09 14:12:33: Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
[DEBUG|connectionpool|L546] 2024-06-09 14:12:34: https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/modules.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 14:12:34: https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/config_sentence_transformers.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 14:12:34: https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/README.md HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 14:12:34: https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/modules.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 14:12:34: https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/sentence_bert_config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 14:12:34: https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 14:12:35: https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 14:12:37: https://huggingface.co:443 "GET /api/models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/revision/main HTTP/1.1" 200 5391
[INFO|SentenceTransformer|L219] 2024-06-09 14:12:38: Use pytorch device_name: cpu
[DEBUG|connectionpool|L546] 2024-06-09 14:12:38: https://huggingface.co:443 "HEAD /gpt2/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 14:12:38: https://huggingface.co:443 "HEAD /meta-llama/Meta-Llama-3-8B/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 14:12:38: https://huggingface.co:443 "HEAD /microsoft/deberta-base/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 14:12:39: https://huggingface.co:443 "HEAD /PlanTL-GOB-ES/roberta-base-bne/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 14:12:39: https://huggingface.co:443 "HEAD /meta-llama/Meta-Llama-3-8B/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 14:12:39: https://huggingface.co:443 "HEAD /gpt2/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 14:12:40: https://huggingface.co:443 "HEAD /meta-llama/Meta-Llama-3-8B/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 14:12:40: https://huggingface.co:443 "HEAD /microsoft/deberta-base/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 14:12:40: https://huggingface.co:443 "HEAD /PlanTL-GOB-ES/roberta-base-bne/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 14:12:41: https://huggingface.co:443 "HEAD /meta-llama/Meta-Llama-3-8B/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
[DEBUG|_config|L80] 2024-06-09 14:12:41: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 14:12:41: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_config|L80] 2024-06-09 14:12:41: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 14:12:41: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|proactor_events|L633] 2024-06-09 14:12:42: Using proactor: IocpProactor
[DEBUG|_config|L80] 2024-06-09 14:12:42: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 14:12:42: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 14:12:42: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 14:12:42: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001C463D26690>
[DEBUG|_trace|L85] 2024-06-09 14:12:42: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001C437BA1EB0> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 14:12:42: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001C43820DF90>
[DEBUG|_trace|L85] 2024-06-09 14:12:42: send_request_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 14:12:42: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 14:12:42: send_request_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 14:12:43: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:12:43: receive_response_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 14:12:44: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 12:12:44 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'4e3f1143-3e0d-4a16-9511-a1de1be75492'), (b'x-correlation-id', b'4db71ce8-92ee-4f01-85c3-d8b94add3d90'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 14:12:44: HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 14:12:44: receive_response_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 14:12:44: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:12:44: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 14:12:44: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 14:12:44: close.started
[DEBUG|_trace|L85] 2024-06-09 14:12:44: close.complete
[DEBUG|_config|L80] 2024-06-09 14:12:45: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 14:12:45: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 14:12:45: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 14:12:45: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001C478DA4F90>
[DEBUG|_trace|L85] 2024-06-09 14:12:45: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001C437BA2CC0> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 14:12:46: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001C438917ED0>
[DEBUG|_trace|L85] 2024-06-09 14:12:46: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:12:46: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 14:12:46: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:12:46: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:12:46: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:12:46: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 12:12:45 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'97ed165a-0c63-4330-bee4-ad12a744ecb2'), (b'x-correlation-id', b'76178b43-a32c-4a56-962b-76f57e12dfbf'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 14:12:46: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-db25-4a74-819c-af090fe3e014 "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 14:12:46: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:12:46: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:12:46: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 14:12:46: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 14:12:46: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:12:46: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 14:12:46: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:12:46: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:12:46: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:12:47: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 12:12:46 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'6020'), (b'Connection', b'keep-alive'), (b'x-session-id', b'a8d6bd32-4f30-48e0-a36f-5f536e3a45f6'), (b'x-correlation-id', b'06f202e7-c792-452f-842f-a06b7e82b6ca'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 14:12:47: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-db25-4a74-819c-af090fe3e014/result/markdown "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 14:12:47: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:12:47: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:12:47: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 14:12:47: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 14:12:47: close.started
[DEBUG|_trace|L85] 2024-06-09 14:12:47: close.complete
[DEBUG|proactor_events|L633] 2024-06-09 14:12:47: Using proactor: IocpProactor
[DEBUG|_config|L80] 2024-06-09 14:12:47: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 14:12:47: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 14:12:47: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 14:12:47: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001C439242F50>
[DEBUG|_trace|L85] 2024-06-09 14:12:47: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001C437BA2B10> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 14:12:47: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001C439242ED0>
[DEBUG|_trace|L85] 2024-06-09 14:12:47: send_request_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 14:12:47: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 14:12:47: send_request_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 14:12:47: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:12:47: receive_response_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 14:12:49: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 12:12:48 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'c96b6207-7ca8-4f4a-8f1d-524939960d91'), (b'x-correlation-id', b'6ae6c3da-7983-4287-b96a-1f2535f4687e'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 14:12:49: HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 14:12:49: receive_response_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 14:12:49: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:12:49: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 14:12:49: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 14:12:49: close.started
[DEBUG|_trace|L85] 2024-06-09 14:12:49: close.complete
[DEBUG|_config|L80] 2024-06-09 14:12:50: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 14:12:50: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 14:12:50: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 14:12:50: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001C431ED4890>
[DEBUG|_trace|L85] 2024-06-09 14:12:50: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001C437BA23C0> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 14:12:50: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001C438915AD0>
[DEBUG|_trace|L85] 2024-06-09 14:12:50: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:12:50: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 14:12:50: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:12:50: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:12:50: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:12:50: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 12:12:50 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'2322e38f-728a-462b-8b54-f4dafca5b135'), (b'x-correlation-id', b'ab6fd3f7-6df3-4e0d-be68-160b29d0087d'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 14:12:50: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-55f7-4e53-be65-4e4a98fadd7e "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 14:12:50: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:12:50: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:12:50: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 14:12:50: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 14:12:50: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:12:50: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 14:12:50: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:12:50: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:12:50: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:12:51: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 12:12:51 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'4083'), (b'Connection', b'keep-alive'), (b'x-session-id', b'a02ce4ee-8cfd-44a2-8da5-d5d63d4cc692'), (b'x-correlation-id', b'7710c558-4308-490e-98c6-8d74355a0a8f'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 14:12:51: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-55f7-4e53-be65-4e4a98fadd7e/result/markdown "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 14:12:51: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:12:51: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:12:51: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 14:12:51: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 14:12:51: close.started
[DEBUG|_trace|L85] 2024-06-09 14:12:51: close.complete
[DEBUG|proactor_events|L633] 2024-06-09 14:12:51: Using proactor: IocpProactor
[DEBUG|_config|L80] 2024-06-09 14:12:51: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 14:12:51: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 14:12:51: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 14:12:51: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001C478DB37D0>
[DEBUG|_trace|L85] 2024-06-09 14:12:51: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001C437BA1EB0> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 14:12:51: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001C437BCABD0>
[DEBUG|_trace|L85] 2024-06-09 14:12:51: send_request_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 14:12:51: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 14:12:51: send_request_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 14:12:52: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:12:52: receive_response_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 14:12:53: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 12:12:52 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'9d396cc2-d65a-4f92-be5b-2835cd4cc187'), (b'x-correlation-id', b'fbfade3c-4742-4d45-aae2-86ab840d8a44'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 14:12:53: HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 14:12:53: receive_response_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 14:12:53: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:12:53: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 14:12:53: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 14:12:53: close.started
[DEBUG|_trace|L85] 2024-06-09 14:12:53: close.complete
[DEBUG|_config|L80] 2024-06-09 14:12:54: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 14:12:54: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 14:12:54: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 14:12:54: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001C478DB2D10>
[DEBUG|_trace|L85] 2024-06-09 14:12:54: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001C437BA2D50> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 14:12:54: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001C478DB2B50>
[DEBUG|_trace|L85] 2024-06-09 14:12:54: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:12:54: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 14:12:54: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:12:54: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:12:54: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:12:55: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 12:12:54 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'4a2e49c6-3e77-4995-808a-1fbf5e25b5b7'), (b'x-correlation-id', b'15b2e91d-b31a-48a0-b706-97d2cbe593df'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 14:12:55: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-0e02-4551-a9ab-1763ad072d12 "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 14:12:55: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:12:55: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:12:55: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 14:12:55: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 14:12:55: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:12:55: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 14:12:55: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:12:55: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 14:12:55: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 14:12:55: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 12:12:55 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'4083'), (b'Connection', b'keep-alive'), (b'x-session-id', b'0e6970bd-2a09-4519-9244-0b99b0cfcf7f'), (b'x-correlation-id', b'254b8623-9545-44e1-bc6d-869b530915ea'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 14:12:55: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-0e02-4551-a9ab-1763ad072d12/result/markdown "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 14:12:55: receive_response_body.started request=<Request [b'GET']>

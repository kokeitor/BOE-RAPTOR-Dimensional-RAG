[DEBUG|base|L311] 2024-06-08 22:06:57: > [SimpleDirectoryReader] Total files added: 9
[DEBUG|base|L311] 2024-06-09 00:19:43: > [SimpleDirectoryReader] Total files added: 9
[DEBUG|base|L311] 2024-06-09 00:27:26: > [SimpleDirectoryReader] Total files added: 9
[INFO|SentenceTransformer|L113] 2024-06-09 00:27:26: Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
[DEBUG|connectionpool|L546] 2024-06-09 00:27:26: https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/modules.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 00:27:26: https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/config_sentence_transformers.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 00:27:26: https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/README.md HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 00:27:27: https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/modules.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 00:27:27: https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/sentence_bert_config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 00:27:27: https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 00:27:27: https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 00:27:30: https://huggingface.co:443 "GET /api/models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/revision/main HTTP/1.1" 200 5391
[INFO|SentenceTransformer|L219] 2024-06-09 00:27:30: Use pytorch device_name: cpu
[INFO|SentenceTransformer|L113] 2024-06-09 00:27:30: Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
[DEBUG|connectionpool|L546] 2024-06-09 00:27:30: https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/modules.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 00:27:30: https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/config_sentence_transformers.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 00:27:30: https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/README.md HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 00:27:30: https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/modules.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 00:27:30: https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/sentence_bert_config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 00:27:31: https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 00:27:31: https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 00:27:33: https://huggingface.co:443 "GET /api/models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/revision/main HTTP/1.1" 200 5391
[INFO|SentenceTransformer|L219] 2024-06-09 00:27:33: Use pytorch device_name: cpu
[DEBUG|connectionpool|L546] 2024-06-09 00:27:34: https://huggingface.co:443 "HEAD /gpt2/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 00:27:34: https://huggingface.co:443 "HEAD /meta-llama/Meta-Llama-3-8B/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 00:27:35: https://huggingface.co:443 "HEAD /microsoft/deberta-base/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 00:27:35: https://huggingface.co:443 "HEAD /PlanTL-GOB-ES/roberta-base-bne/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 00:27:36: https://huggingface.co:443 "HEAD /meta-llama/Meta-Llama-3-8B/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 00:27:37: https://huggingface.co:443 "HEAD /gpt2/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 00:27:37: https://huggingface.co:443 "HEAD /meta-llama/Meta-Llama-3-8B/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 00:27:38: https://huggingface.co:443 "HEAD /microsoft/deberta-base/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 00:27:39: https://huggingface.co:443 "HEAD /PlanTL-GOB-ES/roberta-base-bne/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 00:27:39: https://huggingface.co:443 "HEAD /meta-llama/Meta-Llama-3-8B/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
[DEBUG|_config|L80] 2024-06-09 00:27:40: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 00:27:40: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_config|L80] 2024-06-09 00:27:41: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 00:27:41: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|proactor_events|L633] 2024-06-09 00:27:41: Using proactor: IocpProactor
[DEBUG|_config|L80] 2024-06-09 00:27:41: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 00:27:41: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_config|L80] 2024-06-09 00:27:42: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 00:27:42: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_config|L80] 2024-06-09 00:27:43: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 00:27:43: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_config|L80] 2024-06-09 00:27:43: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 00:27:43: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_config|L80] 2024-06-09 00:27:44: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 00:27:44: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_config|L80] 2024-06-09 00:27:44: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 00:27:44: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_config|L80] 2024-06-09 00:27:45: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 00:27:45: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_config|L80] 2024-06-09 00:27:45: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 00:27:45: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_config|L80] 2024-06-09 00:27:46: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 00:27:46: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 00:27:46: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 00:27:46: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 00:27:46: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 00:27:46: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 00:27:46: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 00:27:46: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 00:27:46: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 00:27:46: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 00:27:46: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 00:27:47: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB71573990>
[DEBUG|_trace|L85] 2024-06-09 00:27:47: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DB49784320> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 00:27:47: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB71571050>
[DEBUG|_trace|L85] 2024-06-09 00:27:47: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DB497840E0> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 00:27:47: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB4CDC8A90>
[DEBUG|_trace|L85] 2024-06-09 00:27:47: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DB49784560> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 00:27:47: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB4CDC8990>
[DEBUG|_trace|L85] 2024-06-09 00:27:47: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DB49784440> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 00:27:47: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB715728D0>
[DEBUG|_trace|L85] 2024-06-09 00:27:47: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DB46CA30B0> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 00:27:47: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB4CDC9010>
[DEBUG|_trace|L85] 2024-06-09 00:27:47: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DB49784CB0> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 00:27:47: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB5D187C10>
[DEBUG|_trace|L85] 2024-06-09 00:27:47: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DB497855B0> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 00:27:47: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB5D185490>
[DEBUG|_trace|L85] 2024-06-09 00:27:47: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DB49785250> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 00:27:47: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB470EB610>
[DEBUG|_trace|L85] 2024-06-09 00:27:47: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DB49785370> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 00:27:47: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB71216AD0>
[DEBUG|_trace|L85] 2024-06-09 00:27:47: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB71214D90>
[DEBUG|_trace|L85] 2024-06-09 00:27:47: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB4780BF90>
[DEBUG|_trace|L85] 2024-06-09 00:27:47: send_request_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 00:27:47: send_request_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 00:27:47: send_request_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 00:27:47: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:47: send_request_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 00:27:47: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:47: send_request_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 00:27:47: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:47: send_request_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 00:27:47: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB5D187B90>
[DEBUG|_trace|L85] 2024-06-09 00:27:47: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB716ACE50>
[DEBUG|_trace|L85] 2024-06-09 00:27:47: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB712163D0>
[DEBUG|_trace|L85] 2024-06-09 00:27:47: send_request_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 00:27:47: send_request_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 00:27:47: send_request_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 00:27:47: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB4A1E08D0>
[DEBUG|_trace|L85] 2024-06-09 00:27:47: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:47: send_request_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 00:27:47: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:47: send_request_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 00:27:47: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:47: send_request_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 00:27:47: send_request_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 00:27:47: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB46CF8350>
[DEBUG|_trace|L85] 2024-06-09 00:27:47: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB715734D0>
[DEBUG|_trace|L85] 2024-06-09 00:27:47: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:47: send_request_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 00:27:47: send_request_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 00:27:47: send_request_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 00:27:47: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:47: send_request_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 00:27:47: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:47: send_request_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 00:27:47: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:47: receive_response_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 00:27:47: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:47: receive_response_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 00:27:47: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:47: receive_response_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 00:27:47: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:47: receive_response_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 00:27:47: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:47: receive_response_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 00:27:48: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:48: receive_response_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 00:27:48: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:48: receive_response_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 00:27:48: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:48: receive_response_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 00:27:48: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:48: receive_response_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 00:27:48: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 08 Jun 2024 22:27:49 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'c7e7d7fd-909d-41e0-acc5-bdabba134b4c'), (b'x-correlation-id', b'e4a85d2b-2abc-498e-8504-862da4bb20bb'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 00:27:48: HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 00:27:48: receive_response_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 00:27:48: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:48: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 00:27:48: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:48: close.started
[DEBUG|_trace|L85] 2024-06-09 00:27:48: close.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:48: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 08 Jun 2024 22:27:49 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'd55b51eb-100c-446d-9d83-a0e9e3aa196f'), (b'x-correlation-id', b'00ea0d20-2b06-4081-a6d5-1dffbf4b3b9d'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 00:27:48: HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 00:27:48: receive_response_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 00:27:48: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:48: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 00:27:48: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:48: close.started
[DEBUG|_trace|L85] 2024-06-09 00:27:48: close.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:48: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 08 Jun 2024 22:27:49 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'785f6326-9387-46b7-acf5-7782da0a6445'), (b'x-correlation-id', b'6faeb7d0-aef4-4507-b3dd-196433b9ab5e'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 00:27:48: HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 00:27:48: receive_response_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 00:27:48: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:48: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 00:27:48: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:48: close.started
[DEBUG|_trace|L85] 2024-06-09 00:27:48: close.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:48: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 08 Jun 2024 22:27:49 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'8785b4c1-7623-48e4-b766-304335e99cd0'), (b'x-correlation-id', b'892b70de-d72d-401f-9463-e35e07b7bd11'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 00:27:48: HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 00:27:48: receive_response_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 00:27:48: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:48: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 00:27:48: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:48: close.started
[DEBUG|_trace|L85] 2024-06-09 00:27:48: close.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:49: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 08 Jun 2024 22:27:49 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'2b9e66e8-c328-4bca-996c-c171fd0e5b21'), (b'x-correlation-id', b'9b6d0e2f-7503-447e-bf06-a2dce87fd72b'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 00:27:49: HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 00:27:49: receive_response_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 00:27:49: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:49: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 00:27:49: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 08 Jun 2024 22:27:49 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'b4f1e5c5-5b4c-49c4-92b4-e9d29bead950'), (b'x-correlation-id', b'b3fcd7a0-0abc-4997-9f87-efa309fc6b37'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 00:27:49: HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 00:27:49: receive_response_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 00:27:49: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:49: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 00:27:49: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:49: close.started
[DEBUG|_trace|L85] 2024-06-09 00:27:49: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:49: close.started
[DEBUG|_trace|L85] 2024-06-09 00:27:49: close.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:49: close.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:49: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 08 Jun 2024 22:27:49 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'29810bee-2069-4029-8d19-6548c96b1a1d'), (b'x-correlation-id', b'b9ab5531-2653-424e-936e-1c60fab318a5'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 00:27:49: HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 00:27:49: receive_response_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 00:27:49: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:49: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 00:27:49: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:49: close.started
[DEBUG|_trace|L85] 2024-06-09 00:27:49: close.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:49: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 08 Jun 2024 22:27:49 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'b93d7082-cf63-4ce0-b32e-0ccf85bfaf97'), (b'x-correlation-id', b'17050c34-bb33-4c2c-b24c-f7cf4a42b183'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 00:27:49: HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 00:27:49: receive_response_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 00:27:49: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:49: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 00:27:49: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:49: close.started
[DEBUG|_trace|L85] 2024-06-09 00:27:49: close.complete
[DEBUG|_config|L80] 2024-06-09 00:27:49: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 00:27:49: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 00:27:50: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 00:27:50: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 08 Jun 2024 22:27:50 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'1dc33107-39ea-480c-bf61-aa5ff9ee8386'), (b'x-correlation-id', b'c40f82ea-93dd-4aa7-8dc2-fceda9ca0914'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 00:27:50: HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 00:27:50: receive_response_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 00:27:50: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:50: response_closed.started
[DEBUG|_config|L80] 2024-06-09 00:27:50: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 00:27:50: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_config|L80] 2024-06-09 00:27:50: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 00:27:50: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_config|L80] 2024-06-09 00:27:51: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 00:27:51: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_config|L80] 2024-06-09 00:27:51: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 00:27:51: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_config|L80] 2024-06-09 00:27:52: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 00:27:52: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_config|L80] 2024-06-09 00:27:52: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 00:27:52: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_config|L80] 2024-06-09 00:27:53: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 00:27:53: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 00:27:53: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:53: close.started
[DEBUG|_trace|L85] 2024-06-09 00:27:53: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 00:27:53: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 00:27:53: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 00:27:53: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 00:27:53: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 00:27:53: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 00:27:53: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 00:27:53: close.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:54: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB4A1E0690>
[DEBUG|_trace|L85] 2024-06-09 00:27:54: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DB49786180> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 00:27:54: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB716AC3D0>
[DEBUG|_trace|L85] 2024-06-09 00:27:54: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DB49786960> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 00:27:54: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB46C90710>
[DEBUG|_trace|L85] 2024-06-09 00:27:54: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DB49786600> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 00:27:54: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB318A79D0>
[DEBUG|_trace|L85] 2024-06-09 00:27:54: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DB49785B50> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 00:27:54: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB4729B690>
[DEBUG|_trace|L85] 2024-06-09 00:27:54: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DB49785F40> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 00:27:54: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB46C901D0>
[DEBUG|_trace|L85] 2024-06-09 00:27:54: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DB49786060> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 00:27:54: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB46C91D90>
[DEBUG|_trace|L85] 2024-06-09 00:27:54: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DB49786C30> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 00:27:54: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB46C91A90>
[DEBUG|_trace|L85] 2024-06-09 00:27:54: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DB49786CC0> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 00:27:54: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB47859350>
[DEBUG|_trace|L85] 2024-06-09 00:27:54: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB4A1E0B90>
[DEBUG|_trace|L85] 2024-06-09 00:27:54: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:27:54: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:27:54: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB46C92190>
[DEBUG|_trace|L85] 2024-06-09 00:27:54: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB4729B150>
[DEBUG|_trace|L85] 2024-06-09 00:27:54: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB46C91210>
[DEBUG|_trace|L85] 2024-06-09 00:27:54: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:54: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:27:54: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:54: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:27:54: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:54: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:27:54: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:54: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:27:54: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:27:54: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:27:54: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:27:54: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB4785A190>
[DEBUG|_trace|L85] 2024-06-09 00:27:54: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB5D146BD0>
[DEBUG|_trace|L85] 2024-06-09 00:27:54: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB47858850>
[DEBUG|_trace|L85] 2024-06-09 00:27:54: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:54: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:27:54: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:54: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:27:54: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:54: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:27:54: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:54: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:27:54: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:54: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:27:54: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:54: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:27:54: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:27:54: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:27:54: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:27:54: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:54: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:27:54: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:54: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:27:54: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:54: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:27:54: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:54: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:27:54: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:54: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:27:54: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:54: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:27:54: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 08 Jun 2024 22:27:54 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'26ce3366-67ed-4b56-ae92-d79cdbf961fe'), (b'x-correlation-id', b'5fc3c922-e34c-43be-9a75-475661dce25e'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 00:27:54: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/4c2c8b77-dd76-44ec-81aa-85901725ff1b "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 00:27:54: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:27:54: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:54: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 00:27:54: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:54: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 08 Jun 2024 22:27:54 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'1c7de671-c93d-407a-9acf-4a96915cc278'), (b'x-correlation-id', b'c54c2e92-3f01-4afb-bfc3-bc16416b1bce'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 00:27:54: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/4522fbba-6bb0-4cdf-bb2e-bc31c0bfe2b6 "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 00:27:54: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:27:54: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:54: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 00:27:54: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:54: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 08 Jun 2024 22:27:54 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'ed85ce8c-d547-44ba-a00c-a53ed01b41b3'), (b'x-correlation-id', b'a91ce4fe-0e64-4b5b-bf1d-7b84cf0a1291'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 00:27:54: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/276dcb88-f5bc-4982-bc41-bcbba9a6f1b0 "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 00:27:54: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:27:54: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:54: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 00:27:54: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:54: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 08 Jun 2024 22:27:54 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'f64cd1e6-2cff-4278-9c83-b05e59ab347e'), (b'x-correlation-id', b'c15a1650-dbbf-4123-8f40-5c5acf73e316'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 00:27:54: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/69e915af-7061-498a-ad90-f90faa2411ae "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 00:27:54: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:27:54: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 08 Jun 2024 22:27:54 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'c6a41a95-e8c4-4c45-ad53-94e0e2aed1cf'), (b'x-correlation-id', b'37afe94e-e3fb-4d62-a186-e012936c04d9'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 00:27:54: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/838df2e7-99b9-4980-9d92-9b3d42f99f99 "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 00:27:54: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:27:54: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:54: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 00:27:54: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:54: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 00:27:54: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:54: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:54: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 08 Jun 2024 22:27:54 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'c52466b8-151b-415f-9eef-41650d263a52'), (b'x-correlation-id', b'b1f6310b-a6a5-457e-b64f-54970bc49bcf'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 00:27:54: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/448f6397-b1d7-4d6b-a1be-52bd1c04cfaa "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 00:27:54: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:27:54: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:54: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 00:27:54: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:54: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 08 Jun 2024 22:27:54 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'8e3547ea-206f-4f90-8484-65ec21e4cf55'), (b'x-correlation-id', b'bd2a909e-bb89-4da5-8d37-0b5415e47e75'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 00:27:54: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/6ac46021-0775-4646-8f3a-af4e0358b3d8 "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 00:27:54: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:27:54: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 08 Jun 2024 22:27:54 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'c38d7209-4893-4a6f-8205-9d98a9d836ff'), (b'x-correlation-id', b'392f0c6f-08ed-4ebc-a425-2bc40db992a9'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 00:27:54: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/ffa44b11-66e5-43af-978c-f0305db4f54a "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 00:27:54: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:27:54: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:54: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 00:27:54: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:54: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 00:27:54: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:54: response_closed.complete
[DEBUG|_config|L80] 2024-06-09 00:27:54: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 00:27:54: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 00:27:55: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 00:27:55: close.started
[DEBUG|_trace|L85] 2024-06-09 00:27:55: close.started
[DEBUG|_trace|L85] 2024-06-09 00:27:55: close.started
[DEBUG|_trace|L85] 2024-06-09 00:27:55: close.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:55: close.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:55: close.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:55: close.started
[DEBUG|_trace|L85] 2024-06-09 00:27:55: close.started
[DEBUG|_trace|L85] 2024-06-09 00:27:55: close.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:55: close.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:55: close.started
[DEBUG|_trace|L85] 2024-06-09 00:27:55: close.started
[DEBUG|_trace|L85] 2024-06-09 00:27:55: close.started
[DEBUG|_trace|L85] 2024-06-09 00:27:55: close.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:55: close.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:55: close.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:55: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB4CDC9950>
[DEBUG|_trace|L85] 2024-06-09 00:27:55: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DB49787DA0> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 00:27:55: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB716AFF50>
[DEBUG|_trace|L85] 2024-06-09 00:27:55: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:27:55: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:55: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:27:55: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:55: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:27:55: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 08 Jun 2024 22:27:56 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'8fdae2bf-afa3-4c32-a04d-feef54434222'), (b'x-correlation-id', b'c7964e62-d7fa-4d17-8459-dfec5c583813'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 00:27:55: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/5bdb5104-2747-4b08-803b-2f1658f0bdeb "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 00:27:55: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:27:55: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:27:55: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 00:27:55: response_closed.complete
[DEBUG|_config|L80] 2024-06-09 00:27:56: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 00:27:56: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_config|L80] 2024-06-09 00:27:56: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 00:27:56: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_config|L80] 2024-06-09 00:27:57: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 00:27:57: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 00:27:58: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 00:27:58: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 00:27:58: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_config|L80] 2024-06-09 00:27:58: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 00:27:58: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_config|L80] 2024-06-09 00:27:58: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 00:27:58: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_config|L80] 2024-06-09 00:27:59: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 00:27:59: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_config|L80] 2024-06-09 00:27:59: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 00:27:59: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_config|L80] 2024-06-09 00:28:00: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 00:28:00: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 00:28:00: close.started
[DEBUG|_trace|L85] 2024-06-09 00:28:00: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 00:28:00: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 00:28:00: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 00:28:00: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 00:28:00: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 00:28:00: close.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:01: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB46D13350>
[DEBUG|_trace|L85] 2024-06-09 00:28:01: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DB497870B0> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 00:28:01: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB318B2BD0>
[DEBUG|_trace|L85] 2024-06-09 00:28:01: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DB497857F0> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 00:28:01: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB46CF8BD0>
[DEBUG|_trace|L85] 2024-06-09 00:28:01: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DB477A0050> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 00:28:01: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB46D13D50>
[DEBUG|_trace|L85] 2024-06-09 00:28:01: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DB497860F0> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 00:28:01: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB71216ED0>
[DEBUG|_trace|L85] 2024-06-09 00:28:01: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DB49786690> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 00:28:01: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB318B2350>
[DEBUG|_trace|L85] 2024-06-09 00:28:01: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DB49785D00> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 00:28:01: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB47104210>
[DEBUG|_trace|L85] 2024-06-09 00:28:01: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DB477A00E0> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 00:28:01: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB47299B90>
[DEBUG|_trace|L85] 2024-06-09 00:28:01: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DB49785BE0> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 00:28:01: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB5D186450>
[DEBUG|_trace|L85] 2024-06-09 00:28:01: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB318B2610>
[DEBUG|_trace|L85] 2024-06-09 00:28:01: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB47104250>
[DEBUG|_trace|L85] 2024-06-09 00:28:01: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:01: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:01: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:01: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB4780B910>
[DEBUG|_trace|L85] 2024-06-09 00:28:01: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB4A1B1E50>
[DEBUG|_trace|L85] 2024-06-09 00:28:01: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:01: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:01: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:01: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:01: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:01: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:01: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:01: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:01: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:01: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:01: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:01: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:01: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:01: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:01: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB469C5850>
[DEBUG|_trace|L85] 2024-06-09 00:28:01: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB5D187F50>
[DEBUG|_trace|L85] 2024-06-09 00:28:01: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB4780B510>
[DEBUG|_trace|L85] 2024-06-09 00:28:01: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:01: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:01: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:01: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:01: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:01: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:01: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:01: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:01: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:01: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:01: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:01: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:01: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:01: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:01: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:01: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:01: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:01: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:01: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:01: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:01: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:01: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:01: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:01: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 08 Jun 2024 22:28:01 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'19d60485-4b8d-4859-abc3-24089ee27d19'), (b'x-correlation-id', b'0eab27fc-78ed-49f3-aaad-1f1d9c37480a'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 00:28:01: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/448f6397-b1d7-4d6b-a1be-52bd1c04cfaa "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 00:28:01: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:01: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:01: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 00:28:01: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:01: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 08 Jun 2024 22:28:01 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'20f5b031-1f35-4924-9d22-233f63a67a25'), (b'x-correlation-id', b'4106f81e-d72e-4cd8-8d2f-cc9b7f4bb435'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 00:28:01: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/838df2e7-99b9-4980-9d92-9b3d42f99f99 "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 00:28:01: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:01: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:01: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 00:28:01: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 08 Jun 2024 22:28:01 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'32fe6caf-71ee-452d-8296-c61eed8b0dd6'), (b'x-correlation-id', b'816f6279-c347-4983-b216-e46eb04ad696'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 00:28:01: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/276dcb88-f5bc-4982-bc41-bcbba9a6f1b0 "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 00:28:01: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:01: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:01: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 00:28:01: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:01: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:01: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 08 Jun 2024 22:28:01 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'32aa3b99-2bd3-4fe3-8723-8b725f664372'), (b'x-correlation-id', b'2709699f-a119-4304-bf8f-d5cd28baf084'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 00:28:01: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/4522fbba-6bb0-4cdf-bb2e-bc31c0bfe2b6 "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 00:28:01: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:01: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:01: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 00:28:01: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 08 Jun 2024 22:28:01 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'dc7c19b5-b6ad-4973-a980-7292454e1c15'), (b'x-correlation-id', b'6290b9f2-8a3a-4e19-afa0-dc7dcd8ffe49'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 00:28:01: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/ffa44b11-66e5-43af-978c-f0305db4f54a "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 00:28:01: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:01: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:01: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 00:28:01: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:01: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:01: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 08 Jun 2024 22:28:01 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'1ac76fda-a9f2-457e-9d78-dfb5e6f080bb'), (b'x-correlation-id', b'71118002-2441-491e-a4ff-0e955e63a187'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 00:28:01: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/6ac46021-0775-4646-8f3a-af4e0358b3d8 "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 00:28:01: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:01: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:01: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 00:28:01: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:01: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 08 Jun 2024 22:28:01 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'13ea2574-273b-47da-83bb-a77b5b7bbb78'), (b'x-correlation-id', b'fa9e12a3-21c7-41a2-8678-9613a7ceb58a'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 00:28:01: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/4c2c8b77-dd76-44ec-81aa-85901725ff1b "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 00:28:01: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:01: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:01: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 00:28:01: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:01: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 08 Jun 2024 22:28:01 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'6abeaa65-480a-4064-b3f5-5afb197d96a7'), (b'x-correlation-id', b'021f8943-d150-4cbe-80b7-d7985a4533e2'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 00:28:01: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/69e915af-7061-498a-ad90-f90faa2411ae "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 00:28:01: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:01: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:01: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 00:28:01: response_closed.complete
[DEBUG|_config|L80] 2024-06-09 00:28:01: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 00:28:01: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 00:28:02: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 00:28:02: close.started
[DEBUG|_trace|L85] 2024-06-09 00:28:02: close.started
[DEBUG|_trace|L85] 2024-06-09 00:28:02: close.started
[DEBUG|_trace|L85] 2024-06-09 00:28:02: close.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:02: close.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:02: close.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:02: close.started
[DEBUG|_trace|L85] 2024-06-09 00:28:02: close.started
[DEBUG|_trace|L85] 2024-06-09 00:28:02: close.started
[DEBUG|_trace|L85] 2024-06-09 00:28:02: close.started
[DEBUG|_trace|L85] 2024-06-09 00:28:02: close.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:02: close.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:02: close.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:02: close.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:02: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB46CFAD10>
[DEBUG|_trace|L85] 2024-06-09 00:28:02: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DB477A0F80> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 00:28:02: close.started
[DEBUG|_trace|L85] 2024-06-09 00:28:02: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB47859550>
[DEBUG|_trace|L85] 2024-06-09 00:28:02: close.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:02: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:02: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:02: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:02: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:02: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:02: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 08 Jun 2024 22:28:03 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'4d4ca0a6-6e1b-4365-aa90-68c9e1d2b5e2'), (b'x-correlation-id', b'f4acc5f7-8a04-423b-b7be-e855200c974e'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 00:28:02: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/5bdb5104-2747-4b08-803b-2f1658f0bdeb "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 00:28:02: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:02: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:02: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 00:28:02: response_closed.complete
[DEBUG|_config|L80] 2024-06-09 00:28:03: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 00:28:03: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_config|L80] 2024-06-09 00:28:03: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 00:28:03: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_config|L80] 2024-06-09 00:28:04: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 00:28:04: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_config|L80] 2024-06-09 00:28:05: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 00:28:05: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_config|L80] 2024-06-09 00:28:05: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 00:28:05: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_config|L80] 2024-06-09 00:28:06: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 00:28:06: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_config|L80] 2024-06-09 00:28:06: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 00:28:06: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 00:28:07: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 00:28:07: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 00:28:07: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 00:28:07: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 00:28:07: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 00:28:07: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 00:28:07: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_config|L80] 2024-06-09 00:28:07: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 00:28:07: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 00:28:07: close.started
[DEBUG|_trace|L85] 2024-06-09 00:28:07: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 00:28:07: close.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:07: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB47771210>
[DEBUG|_trace|L85] 2024-06-09 00:28:07: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DB477A0D40> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 00:28:07: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB47770510>
[DEBUG|_trace|L85] 2024-06-09 00:28:07: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DB46CA30B0> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 00:28:07: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB477706D0>
[DEBUG|_trace|L85] 2024-06-09 00:28:07: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DB477A0710> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 00:28:07: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB47770310>
[DEBUG|_trace|L85] 2024-06-09 00:28:07: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DB477A07A0> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 00:28:07: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB47758E10>
[DEBUG|_trace|L85] 2024-06-09 00:28:07: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DB477A0B00> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 00:28:07: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB47758190>
[DEBUG|_trace|L85] 2024-06-09 00:28:07: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DB477A09E0> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 00:28:07: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB71566690>
[DEBUG|_trace|L85] 2024-06-09 00:28:07: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DB477A1520> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 00:28:07: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB47759990>
[DEBUG|_trace|L85] 2024-06-09 00:28:07: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DB477A0320> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 00:28:07: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB484CC910>
[DEBUG|_trace|L85] 2024-06-09 00:28:07: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB47766C10>
[DEBUG|_trace|L85] 2024-06-09 00:28:07: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB5CFFF7D0>
[DEBUG|_trace|L85] 2024-06-09 00:28:07: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB5CFFE9D0>
[DEBUG|_trace|L85] 2024-06-09 00:28:07: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:07: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:07: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:07: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:07: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB4775CF50>
[DEBUG|_trace|L85] 2024-06-09 00:28:07: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB5CFFE1D0>
[DEBUG|_trace|L85] 2024-06-09 00:28:07: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB4775F350>
[DEBUG|_trace|L85] 2024-06-09 00:28:07: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB47771310>
[DEBUG|_trace|L85] 2024-06-09 00:28:07: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:08: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:08: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:08: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:08: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:08: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:08: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:08: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:08: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:08: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:08: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:08: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:08: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:08: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:08: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:08: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:08: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:08: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:08: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:08: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:08: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:08: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:08: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:08: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:08: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:08: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:08: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:08: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:08: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:08: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:08: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:08: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:08: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:08: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:08: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:08: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:08: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 08 Jun 2024 22:28:08 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'd86f499b-b13a-4275-808c-a848c81cb33d'), (b'x-correlation-id', b'a1587500-912b-4469-8038-974385e95483'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 00:28:08: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/448f6397-b1d7-4d6b-a1be-52bd1c04cfaa "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 00:28:08: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:08: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:08: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 00:28:08: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:08: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 08 Jun 2024 22:28:08 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'fa3e4864-2485-45d1-bd44-b2deaed0fbb6'), (b'x-correlation-id', b'3938e0b2-6df3-49fe-923a-e4c3c7cac349'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 00:28:08: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/4c2c8b77-dd76-44ec-81aa-85901725ff1b "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 00:28:08: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:08: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:08: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 00:28:08: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:08: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 08 Jun 2024 22:28:08 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'b5acc9cc-004e-4242-9b4b-ddfade8a8572'), (b'x-correlation-id', b'9ed18602-f095-45d5-9ea7-76902c934cf0'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 00:28:08: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/6ac46021-0775-4646-8f3a-af4e0358b3d8 "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 00:28:08: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:08: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:08: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 00:28:08: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:08: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 08 Jun 2024 22:28:08 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'a319d88e-590c-4cc6-8cea-d9367f1b11b6'), (b'x-correlation-id', b'bcdb89dc-d260-4e04-9ee9-f2eeaab97ec0'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 00:28:08: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/838df2e7-99b9-4980-9d92-9b3d42f99f99 "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 00:28:08: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:08: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:08: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 00:28:08: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:08: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 08 Jun 2024 22:28:08 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'e5186527-44e1-4d1b-b63b-49d2510d4af3'), (b'x-correlation-id', b'8a5ce984-b3f2-41b3-89fb-ebab24eef51c'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 00:28:08: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/ffa44b11-66e5-43af-978c-f0305db4f54a "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 00:28:08: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:08: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:08: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 00:28:08: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:08: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 08 Jun 2024 22:28:08 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'ecb8a066-2f22-419c-8852-6265849020a8'), (b'x-correlation-id', b'fae7d1c6-e794-47df-869c-9946fba01d5e'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 00:28:08: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/4522fbba-6bb0-4cdf-bb2e-bc31c0bfe2b6 "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 00:28:08: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:08: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:08: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 00:28:08: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:08: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 08 Jun 2024 22:28:08 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'71987b65-ca2c-40d4-991a-4977ebc70ba4'), (b'x-correlation-id', b'bf0d7026-a0df-4ac9-b71c-1c0949868791'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 00:28:08: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/69e915af-7061-498a-ad90-f90faa2411ae "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 00:28:08: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:08: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:08: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 00:28:08: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:08: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 08 Jun 2024 22:28:08 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'66ea4031-22bc-4e81-be88-66c85e7832ae'), (b'x-correlation-id', b'706128a3-36f3-4519-b43b-64912d74a114'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 00:28:08: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/276dcb88-f5bc-4982-bc41-bcbba9a6f1b0 "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 00:28:08: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:08: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:08: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 00:28:08: response_closed.complete
[DEBUG|_config|L80] 2024-06-09 00:28:08: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 00:28:08: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 00:28:09: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 00:28:09: close.started
[DEBUG|_trace|L85] 2024-06-09 00:28:09: close.started
[DEBUG|_trace|L85] 2024-06-09 00:28:09: close.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:09: close.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:09: close.started
[DEBUG|_trace|L85] 2024-06-09 00:28:09: close.started
[DEBUG|_trace|L85] 2024-06-09 00:28:09: close.started
[DEBUG|_trace|L85] 2024-06-09 00:28:09: close.started
[DEBUG|_trace|L85] 2024-06-09 00:28:09: close.started
[DEBUG|_trace|L85] 2024-06-09 00:28:09: close.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:09: close.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:09: close.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:09: close.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:09: close.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:09: close.started
[DEBUG|_trace|L85] 2024-06-09 00:28:09: close.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:09: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB47771290>
[DEBUG|_trace|L85] 2024-06-09 00:28:09: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DB477A1EB0> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 00:28:09: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB47758810>
[DEBUG|_trace|L85] 2024-06-09 00:28:09: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:09: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:09: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:09: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:09: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:09: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 08 Jun 2024 22:28:09 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'c535d065-8324-4037-8330-40ce4b68302c'), (b'x-correlation-id', b'a13c52cc-b04e-451a-ab24-3ae16df3675a'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 00:28:09: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/5bdb5104-2747-4b08-803b-2f1658f0bdeb "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 00:28:09: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:09: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:09: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 00:28:09: response_closed.complete
[DEBUG|_config|L80] 2024-06-09 00:28:10: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 00:28:10: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_config|L80] 2024-06-09 00:28:10: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 00:28:10: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 00:28:11: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 00:28:11: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_config|L80] 2024-06-09 00:28:11: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 00:28:11: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_config|L80] 2024-06-09 00:28:11: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 00:28:11: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_config|L80] 2024-06-09 00:28:12: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 00:28:12: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_config|L80] 2024-06-09 00:28:12: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 00:28:12: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_config|L80] 2024-06-09 00:28:13: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 00:28:13: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_config|L80] 2024-06-09 00:28:14: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 00:28:14: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 00:28:14: close.started
[DEBUG|_trace|L85] 2024-06-09 00:28:14: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 00:28:14: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 00:28:14: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 00:28:14: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 00:28:14: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 00:28:14: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 00:28:14: close.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:14: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB4774E910>
[DEBUG|_trace|L85] 2024-06-09 00:28:14: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DB477A19A0> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 00:28:14: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB4778EAD0>
[DEBUG|_trace|L85] 2024-06-09 00:28:14: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DB477A1C70> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 00:28:14: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB4774E490>
[DEBUG|_trace|L85] 2024-06-09 00:28:14: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DB49785640> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 00:28:14: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB47790390>
[DEBUG|_trace|L85] 2024-06-09 00:28:14: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DB477A1370> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 00:28:14: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB477256D0>
[DEBUG|_trace|L85] 2024-06-09 00:28:14: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DB477A0680> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 00:28:14: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB4774C3D0>
[DEBUG|_trace|L85] 2024-06-09 00:28:14: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DB477A1760> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 00:28:14: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB4774C290>
[DEBUG|_trace|L85] 2024-06-09 00:28:14: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DB477A0E60> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 00:28:14: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB4774CDD0>
[DEBUG|_trace|L85] 2024-06-09 00:28:14: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DB477A1400> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 00:28:14: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB4774E990>
[DEBUG|_trace|L85] 2024-06-09 00:28:14: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB4774E750>
[DEBUG|_trace|L85] 2024-06-09 00:28:14: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB47791250>
[DEBUG|_trace|L85] 2024-06-09 00:28:14: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:14: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:14: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:14: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:14: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:14: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:14: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:14: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:14: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:14: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:14: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:14: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:14: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:14: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:14: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:14: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB4774D750>
[DEBUG|_trace|L85] 2024-06-09 00:28:14: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB477A7210>
[DEBUG|_trace|L85] 2024-06-09 00:28:14: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB477902D0>
[DEBUG|_trace|L85] 2024-06-09 00:28:14: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB47793010>
[DEBUG|_trace|L85] 2024-06-09 00:28:14: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:14: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:14: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:14: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:14: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001DB477A5690>
[DEBUG|_trace|L85] 2024-06-09 00:28:14: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:14: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:14: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:14: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:14: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:14: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:14: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 00:28:14: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 00:28:14: send_request_headers.complete

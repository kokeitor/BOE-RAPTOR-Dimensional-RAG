[DEBUG|_trace|L85] 2024-06-09 13:48:12: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:12: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 11:48:12 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'd9a87a19-4188-4140-a4ff-48e00478c893'), (b'x-correlation-id', b'6ef393d0-7b8f-49ed-ab25-0aae4ba0b783'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 13:48:12: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-7739-4d44-9a7a-ebe44f747d86 "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 13:48:12: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:13: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:13: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 13:48:13: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:13: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:13: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:13: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:13: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:13: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:13: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 11:48:13 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'6020'), (b'Connection', b'keep-alive'), (b'x-session-id', b'3230b3cc-1e84-4244-ab2b-a5c3dcd1dd83'), (b'x-correlation-id', b'8bf3afdf-3ec3-413b-b7af-b778d8eccac3'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 13:48:13: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-7739-4d44-9a7a-ebe44f747d86/result/markdown "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 13:48:13: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:13: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:13: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 13:48:13: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:13: close.started
[DEBUG|_trace|L85] 2024-06-09 13:48:13: close.complete
[DEBUG|proactor_events|L633] 2024-06-09 13:48:13: Using proactor: IocpProactor
[DEBUG|_config|L80] 2024-06-09 13:48:13: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 13:48:13: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 13:48:14: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 13:48:14: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001E8B7118090>
[DEBUG|_trace|L85] 2024-06-09 13:48:14: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001E8CCBBD6D0> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 13:48:15: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001E8B6A2B210>
[DEBUG|_trace|L85] 2024-06-09 13:48:15: send_request_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:48:15: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:15: send_request_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:48:15: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:15: receive_response_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:48:16: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 11:48:16 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'049343da-0b7e-4079-8eb4-bf1bd80128ba'), (b'x-correlation-id', b'8ec10562-abf0-43c6-a822-9c23efba94be'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 13:48:16: HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 13:48:16: receive_response_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:48:16: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:16: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 13:48:16: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:16: close.started
[DEBUG|_trace|L85] 2024-06-09 13:48:16: close.complete
[DEBUG|_config|L80] 2024-06-09 13:48:17: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 13:48:17: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 13:48:19: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 13:48:19: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001E8CCBF5350>
[DEBUG|_trace|L85] 2024-06-09 13:48:19: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001E8CCBBD910> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 13:48:19: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001E8B75E98D0>
[DEBUG|_trace|L85] 2024-06-09 13:48:19: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:19: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:19: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:19: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:19: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:20: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 11:48:19 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'0f41d6d4-59f2-4f2c-849c-9404c19bb81d'), (b'x-correlation-id', b'8bbca8ee-bad4-4318-a1d9-06440f06631b'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 13:48:20: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-64de-4726-9e5f-b1065207b0b7 "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 13:48:20: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:20: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:20: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 13:48:20: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:20: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:20: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:20: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:20: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:20: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:20: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 11:48:20 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'4083'), (b'Connection', b'keep-alive'), (b'x-session-id', b'3cea0e5f-b0e3-473b-9546-b2079627287f'), (b'x-correlation-id', b'f11b5049-988c-4799-8bfd-9c294a5688c3'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 13:48:20: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-64de-4726-9e5f-b1065207b0b7/result/markdown "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 13:48:20: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:20: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:20: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 13:48:20: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:20: close.started
[DEBUG|_trace|L85] 2024-06-09 13:48:20: close.complete
[DEBUG|proactor_events|L633] 2024-06-09 13:48:20: Using proactor: IocpProactor
[DEBUG|_config|L80] 2024-06-09 13:48:20: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 13:48:20: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 13:48:21: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 13:48:21: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001E8A121CB50>
[DEBUG|_trace|L85] 2024-06-09 13:48:21: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001E8CCBBE720> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 13:48:21: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001E8CCBF6250>
[DEBUG|_trace|L85] 2024-06-09 13:48:21: send_request_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:48:21: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:21: send_request_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:48:22: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:22: receive_response_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:48:23: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 11:48:22 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'b3952ecb-0784-431a-be8e-d416846f7a5a'), (b'x-correlation-id', b'b3259c6c-7fc2-4181-bc23-b82964eaa68b'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 13:48:23: HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 13:48:23: receive_response_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:48:23: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:23: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 13:48:23: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:23: close.started
[DEBUG|_trace|L85] 2024-06-09 13:48:23: close.complete
[DEBUG|_config|L80] 2024-06-09 13:48:24: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 13:48:24: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 13:48:25: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 13:48:25: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001E8B7072FD0>
[DEBUG|_trace|L85] 2024-06-09 13:48:25: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001E8CCBBE4E0> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 13:48:25: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001E8B7072D50>
[DEBUG|_trace|L85] 2024-06-09 13:48:25: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:25: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:25: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:25: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:25: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:26: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 11:48:25 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'e91eeefc-1275-46b3-99ed-5b8645181613'), (b'x-correlation-id', b'a232ff0a-b4cb-4ff5-ad2d-0c168809ed63'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 13:48:26: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-f66b-4e31-aeae-a40f2825bd68 "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 13:48:26: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:26: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:26: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 13:48:26: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:26: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:26: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:26: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:26: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:26: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:26: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 11:48:26 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'4083'), (b'Connection', b'keep-alive'), (b'x-session-id', b'6115df78-6eb6-4ffb-9eb9-76557ce01bf5'), (b'x-correlation-id', b'ed7c822d-36d7-4b27-9131-fdff88c18412'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 13:48:26: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-f66b-4e31-aeae-a40f2825bd68/result/markdown "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 13:48:26: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:26: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:26: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 13:48:26: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:26: close.started
[DEBUG|_trace|L85] 2024-06-09 13:48:26: close.complete
[DEBUG|proactor_events|L633] 2024-06-09 13:48:26: Using proactor: IocpProactor
[DEBUG|_config|L80] 2024-06-09 13:48:26: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 13:48:26: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 13:48:27: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 13:48:27: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001E8B7072790>
[DEBUG|_trace|L85] 2024-06-09 13:48:27: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001E8CCBBE7B0> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 13:48:27: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001E8B63446D0>
[DEBUG|_trace|L85] 2024-06-09 13:48:27: send_request_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:48:27: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:27: send_request_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:48:28: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:28: receive_response_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:48:29: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 11:48:29 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'd07bfb0b-1b6c-416f-98a5-86cd30aab9fe'), (b'x-correlation-id', b'ccd43ae9-24fd-475b-9b8c-63bc818e0363'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 13:48:29: HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 13:48:29: receive_response_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:48:29: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:29: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 13:48:29: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:29: close.started
[DEBUG|_trace|L85] 2024-06-09 13:48:29: close.complete
[DEBUG|_config|L80] 2024-06-09 13:48:30: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 13:48:30: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 13:48:31: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 13:48:31: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001E8B63D44D0>
[DEBUG|_trace|L85] 2024-06-09 13:48:31: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001E8CCBBF650> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 13:48:31: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001E8E0AA1650>
[DEBUG|_trace|L85] 2024-06-09 13:48:31: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:31: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:31: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:31: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:31: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:31: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 11:48:31 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'baea7dff-e222-40e8-a471-6871b076a5b2'), (b'x-correlation-id', b'673e17aa-9e07-4341-887b-237a3e69ed25'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 13:48:31: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-e8a8-4253-8439-43a232a15a82 "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 13:48:31: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:31: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:31: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 13:48:31: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:31: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:31: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:31: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:31: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:31: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:32: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 11:48:31 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'233734'), (b'Connection', b'keep-alive'), (b'x-session-id', b'0b3d4f3f-600c-4734-a3e6-186745733771'), (b'x-correlation-id', b'a172fdff-151e-4e49-aff6-02b9e22915af'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 13:48:32: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-e8a8-4253-8439-43a232a15a82/result/markdown "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 13:48:32: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:32: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:32: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 13:48:32: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:32: close.started
[DEBUG|_trace|L85] 2024-06-09 13:48:32: close.complete
[DEBUG|proactor_events|L633] 2024-06-09 13:48:32: Using proactor: IocpProactor
[DEBUG|_config|L80] 2024-06-09 13:48:32: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 13:48:32: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 13:48:33: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 13:48:33: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001E8B63D4E90>
[DEBUG|_trace|L85] 2024-06-09 13:48:33: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001E8CCBBE570> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 13:48:33: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001E8B7071790>
[DEBUG|_trace|L85] 2024-06-09 13:48:33: send_request_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:48:33: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:33: send_request_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:48:33: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:33: receive_response_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:48:35: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 11:48:34 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'3a47db68-05cf-4589-b9c2-c4a148d94a0b'), (b'x-correlation-id', b'513e7a72-1348-4049-9f0a-5696536298cd'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 13:48:35: HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 13:48:35: receive_response_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:48:35: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:35: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 13:48:35: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:35: close.started
[DEBUG|_trace|L85] 2024-06-09 13:48:35: close.complete
[DEBUG|_config|L80] 2024-06-09 13:48:36: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 13:48:36: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 13:48:38: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 13:48:38: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001E8B7073910>
[DEBUG|_trace|L85] 2024-06-09 13:48:38: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001E8CCBBE960> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 13:48:39: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001E8E0CAB950>
[DEBUG|_trace|L85] 2024-06-09 13:48:39: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:39: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:39: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:39: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:39: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:39: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 11:48:38 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'6713d7a8-3a70-4917-8873-b23e79aa350e'), (b'x-correlation-id', b'e164df64-e0ca-4ce5-b4f8-ace24bb9c352'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 13:48:39: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-d0a2-4321-a6c4-4d59d3a3078d "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 13:48:39: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:39: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:39: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 13:48:39: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:39: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:39: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:39: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:39: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:39: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:39: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 11:48:39 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'8463'), (b'Connection', b'keep-alive'), (b'x-session-id', b'33661b90-b8db-4d34-a0da-bb0ac01eb6a3'), (b'x-correlation-id', b'67dae25c-989a-4385-a689-9ee27bb9eed2'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 13:48:39: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-d0a2-4321-a6c4-4d59d3a3078d/result/markdown "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 13:48:39: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:39: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:39: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 13:48:39: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:39: close.started
[DEBUG|_trace|L85] 2024-06-09 13:48:39: close.complete
[DEBUG|proactor_events|L633] 2024-06-09 13:48:39: Using proactor: IocpProactor
[DEBUG|_config|L80] 2024-06-09 13:48:39: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 13:48:39: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 13:48:40: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 13:48:40: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001E8B6346790>
[DEBUG|_trace|L85] 2024-06-09 13:48:40: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001E8CCBBF770> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 13:48:40: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001E8B63D49D0>
[DEBUG|_trace|L85] 2024-06-09 13:48:40: send_request_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:48:40: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:40: send_request_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:48:40: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:40: receive_response_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:48:42: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 11:48:41 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'6c24a078-61a0-4c39-80a6-e4d18120eac4'), (b'x-correlation-id', b'0cb9141d-eda6-46b6-9bb5-aa33380f0804'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 13:48:42: HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 13:48:42: receive_response_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:48:42: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:42: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 13:48:42: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:42: close.started
[DEBUG|_trace|L85] 2024-06-09 13:48:42: close.complete
[DEBUG|_config|L80] 2024-06-09 13:48:43: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 13:48:43: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 13:48:44: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 13:48:44: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001E8B8D95E90>
[DEBUG|_trace|L85] 2024-06-09 13:48:44: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001E8CCBBE600> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 13:48:44: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001E8CCBF4ED0>
[DEBUG|_trace|L85] 2024-06-09 13:48:44: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:44: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:44: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:44: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:44: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:44: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 11:48:44 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'53ddd594-09ea-422b-a4c5-592dc37640cd'), (b'x-correlation-id', b'7f196d86-2979-4e9b-9490-d82ff76d7124'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 13:48:44: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-5410-4fa1-8614-169939e1d159 "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 13:48:44: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:44: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:44: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 13:48:44: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:44: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:44: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:44: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:44: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:44: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:45: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 11:48:44 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'12669'), (b'Connection', b'keep-alive'), (b'x-session-id', b'377bcb1b-39ec-4592-add8-2cf9300b1b4c'), (b'x-correlation-id', b'5da17f76-d427-4909-8cdb-209e6e51331b'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 13:48:45: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-5410-4fa1-8614-169939e1d159/result/markdown "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 13:48:45: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:45: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:45: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 13:48:45: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:45: close.started
[DEBUG|_trace|L85] 2024-06-09 13:48:45: close.complete
[DEBUG|proactor_events|L633] 2024-06-09 13:48:45: Using proactor: IocpProactor
[DEBUG|_config|L80] 2024-06-09 13:48:45: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 13:48:45: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 13:48:46: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 13:48:46: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001E89491A350>
[DEBUG|_trace|L85] 2024-06-09 13:48:46: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001E8BC6400E0> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 13:48:46: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001E8B7072A50>
[DEBUG|_trace|L85] 2024-06-09 13:48:46: send_request_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:48:46: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:46: send_request_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:48:46: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:46: receive_response_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:48:47: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 11:48:47 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'3dcc3db2-d91d-4c8d-b25e-a742a498cf08'), (b'x-correlation-id', b'7ae82802-ed36-42c6-abfc-e31ea2f02abe'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 13:48:47: HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 13:48:47: receive_response_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:48:47: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:47: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 13:48:47: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:47: close.started
[DEBUG|_trace|L85] 2024-06-09 13:48:47: close.complete
[DEBUG|_config|L80] 2024-06-09 13:48:48: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 13:48:48: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 13:48:49: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 13:48:49: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001E8CCBF4B10>
[DEBUG|_trace|L85] 2024-06-09 13:48:49: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001E8BC640320> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 13:48:49: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001E8CCBF4BD0>
[DEBUG|_trace|L85] 2024-06-09 13:48:49: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:49: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:49: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:49: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:49: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:50: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 11:48:49 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'0e96a9c2-dfd0-4d7b-b94b-429dcf958aee'), (b'x-correlation-id', b'b8594b61-c109-4622-9242-788031475fc3'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 13:48:50: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-4b2f-435f-be93-46d698bd447a "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 13:48:50: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:50: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:50: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 13:48:50: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:50: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:50: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:50: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:50: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:50: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:50: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 11:48:50 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'1341'), (b'Connection', b'keep-alive'), (b'x-session-id', b'87c476f9-f111-4a8b-ae2e-a23017c10093'), (b'x-correlation-id', b'4b1cbdba-0542-401a-8f92-d1ad7e226b48'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 13:48:50: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-4b2f-435f-be93-46d698bd447a/result/markdown "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 13:48:50: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:50: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:50: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 13:48:50: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:50: close.started
[DEBUG|_trace|L85] 2024-06-09 13:48:50: close.complete
[DEBUG|proactor_events|L633] 2024-06-09 13:48:50: Using proactor: IocpProactor
[DEBUG|_config|L80] 2024-06-09 13:48:50: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 13:48:50: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 13:48:51: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 13:48:51: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001E8E0C6AA90>
[DEBUG|_trace|L85] 2024-06-09 13:48:51: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001E8CCBBFDA0> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 13:48:51: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001E8CCBF63D0>
[DEBUG|_trace|L85] 2024-06-09 13:48:51: send_request_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:48:51: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:51: send_request_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:48:51: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:51: receive_response_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:48:53: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 11:48:53 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'5021dd36-532b-4a41-b9d2-6f972ead5d31'), (b'x-correlation-id', b'ffff8aac-bb10-4456-ab29-f5fa9518b25d'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 13:48:53: HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 13:48:53: receive_response_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:48:53: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:53: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 13:48:53: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:53: close.started
[DEBUG|_trace|L85] 2024-06-09 13:48:53: close.complete
[DEBUG|_config|L80] 2024-06-09 13:48:54: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 13:48:54: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 13:48:55: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 13:48:55: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001E8E0AA2D10>
[DEBUG|_trace|L85] 2024-06-09 13:48:55: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001E8CCBBD910> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 13:48:55: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001E8E0AA0E90>
[DEBUG|_trace|L85] 2024-06-09 13:48:55: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:55: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:55: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:55: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:55: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:55: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 11:48:55 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'1962abfb-6757-4251-86b3-5f15275c50fd'), (b'x-correlation-id', b'82b0406c-8797-4687-9701-f592f3464833'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 13:48:55: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-c31f-42d7-844d-af90058b9a9d "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 13:48:55: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:55: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:55: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 13:48:55: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:55: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:55: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:55: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:55: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:55: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:56: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 11:48:55 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'1464'), (b'Connection', b'keep-alive'), (b'x-session-id', b'68312d6c-b140-49c9-8c2d-f1b6fd2d96a6'), (b'x-correlation-id', b'48c4998d-c0a2-4b72-a14a-e74f1bdab9be'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 13:48:56: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-c31f-42d7-844d-af90058b9a9d/result/markdown "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 13:48:56: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:48:56: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:56: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 13:48:56: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:56: close.started
[DEBUG|_trace|L85] 2024-06-09 13:48:56: close.complete
[DEBUG|proactor_events|L633] 2024-06-09 13:48:56: Using proactor: IocpProactor
[DEBUG|_config|L80] 2024-06-09 13:48:56: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 13:48:56: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 13:48:56: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 13:48:56: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001E8A1205710>
[DEBUG|_trace|L85] 2024-06-09 13:48:56: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001E8CCBBFAD0> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 13:48:57: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001E8B8D96E50>
[DEBUG|_trace|L85] 2024-06-09 13:48:57: send_request_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:48:57: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:57: send_request_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:48:57: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:57: receive_response_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:48:59: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 11:48:59 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'944ce78c-2990-45bf-b290-83bb31510081'), (b'x-correlation-id', b'db3ca19e-48e5-4f45-baa7-a66429eb11fb'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 13:48:59: HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 13:48:59: receive_response_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:48:59: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:59: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 13:48:59: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 13:48:59: close.started
[DEBUG|_trace|L85] 2024-06-09 13:48:59: close.complete
[DEBUG|_config|L80] 2024-06-09 13:49:00: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 13:49:00: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 13:49:01: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 13:49:01: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001E8B70730D0>
[DEBUG|_trace|L85] 2024-06-09 13:49:01: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001E8BC6407A0> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 13:49:01: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001E8E0BFDE50>
[DEBUG|_trace|L85] 2024-06-09 13:49:01: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:49:01: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 13:49:01: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:49:01: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:49:01: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:49:01: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 11:49:01 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'3d876da4-8800-4d81-8795-73e353ad8d2d'), (b'x-correlation-id', b'2fd5dbf1-b9bd-4bcd-a7d3-3f5c5d773bc5'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 13:49:01: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-eda1-4415-aecf-aed6d16b2022 "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 13:49:01: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:49:01: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:49:01: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 13:49:01: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 13:49:01: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:49:01: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 13:49:01: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:49:01: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:49:01: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:49:02: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 11:49:01 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'886414'), (b'Connection', b'keep-alive'), (b'x-session-id', b'45e0be40-85f0-46e4-adbc-9df94420a3ac'), (b'x-correlation-id', b'afabdeb7-be7a-4ff6-a7dc-d9bd5c0bbcfa'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 13:49:02: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-eda1-4415-aecf-aed6d16b2022/result/markdown "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 13:49:02: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:49:03: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:49:03: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 13:49:03: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 13:49:03: close.started
[DEBUG|_trace|L85] 2024-06-09 13:49:03: close.complete
[INFO|parsers|L84] 2024-06-09 13:49:07: Parsed num of docs -> 9
[INFO|etl|L255] 2024-06-09 13:49:07: Configuration of TextPreprocess for task : classification founded
[DEBUG|etl|L259] 2024-06-09 13:49:07: Trying to preprocess texts --> del_stopwords : {'apply': True, 'lang': 'Spanish'}
[DEBUG|base|L311] 2024-06-09 13:50:24: > [SimpleDirectoryReader] Total files added: 9
[INFO|SentenceTransformer|L113] 2024-06-09 13:50:24: Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
[DEBUG|connectionpool|L546] 2024-06-09 13:50:24: https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/modules.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 13:50:24: https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/config_sentence_transformers.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 13:50:24: https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/README.md HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 13:50:24: https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/modules.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 13:50:24: https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/sentence_bert_config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 13:50:24: https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 13:50:26: https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 13:50:28: https://huggingface.co:443 "GET /api/models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/revision/main HTTP/1.1" 200 5391
[INFO|SentenceTransformer|L219] 2024-06-09 13:50:28: Use pytorch device_name: cpu
[INFO|SentenceTransformer|L113] 2024-06-09 13:50:28: Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
[DEBUG|connectionpool|L546] 2024-06-09 13:50:28: https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/modules.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 13:50:29: https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/config_sentence_transformers.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 13:50:29: https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/README.md HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 13:50:29: https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/modules.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 13:50:29: https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/sentence_bert_config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 13:50:29: https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 13:50:30: https://huggingface.co:443 "HEAD /sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 13:50:33: https://huggingface.co:443 "GET /api/models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/revision/main HTTP/1.1" 200 5391
[INFO|SentenceTransformer|L219] 2024-06-09 13:50:33: Use pytorch device_name: cpu
[DEBUG|connectionpool|L546] 2024-06-09 13:50:33: https://huggingface.co:443 "HEAD /gpt2/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 13:50:34: https://huggingface.co:443 "HEAD /meta-llama/Meta-Llama-3-8B/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 13:50:35: https://huggingface.co:443 "HEAD /microsoft/deberta-base/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 13:50:35: https://huggingface.co:443 "HEAD /PlanTL-GOB-ES/roberta-base-bne/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 13:50:35: https://huggingface.co:443 "HEAD /meta-llama/Meta-Llama-3-8B/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 13:50:36: https://huggingface.co:443 "HEAD /gpt2/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 13:50:36: https://huggingface.co:443 "HEAD /meta-llama/Meta-Llama-3-8B/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 13:50:37: https://huggingface.co:443 "HEAD /microsoft/deberta-base/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 13:50:38: https://huggingface.co:443 "HEAD /PlanTL-GOB-ES/roberta-base-bne/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
[DEBUG|connectionpool|L546] 2024-06-09 13:50:38: https://huggingface.co:443 "HEAD /meta-llama/Meta-Llama-3-8B/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
[DEBUG|_config|L80] 2024-06-09 13:50:39: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 13:50:39: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_config|L80] 2024-06-09 13:50:39: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 13:50:39: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|proactor_events|L633] 2024-06-09 13:50:40: Using proactor: IocpProactor
[DEBUG|_config|L80] 2024-06-09 13:50:40: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 13:50:40: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 13:50:41: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 13:50:41: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x00000152FB1E61D0>
[DEBUG|_trace|L85] 2024-06-09 13:50:41: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000015310DA5760> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 13:50:41: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x00000152FA280890>
[DEBUG|_trace|L85] 2024-06-09 13:50:41: send_request_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:50:41: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 13:50:41: send_request_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:50:42: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:50:42: receive_response_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:50:43: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 11:50:42 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'543ab0a6-9a84-4aa7-b38f-100bfc4d89ae'), (b'x-correlation-id', b'2d0f9bbc-3eb1-4fb5-a833-77e956b8d5d4'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 13:50:43: HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 13:50:43: receive_response_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:50:43: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:50:43: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 13:50:43: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 13:50:43: close.started
[DEBUG|_trace|L85] 2024-06-09 13:50:43: close.complete
[DEBUG|_config|L80] 2024-06-09 13:50:44: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 13:50:44: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 13:50:44: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 13:50:45: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x00000152DC25B390>
[DEBUG|_trace|L85] 2024-06-09 13:50:45: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000015310DA6570> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 13:50:45: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x00000152FA355B10>
[DEBUG|_trace|L85] 2024-06-09 13:50:45: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:50:45: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 13:50:45: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:50:45: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:50:45: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:50:45: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 11:50:44 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'cd9ec758-930b-4af5-b40e-a6fb9131cb5b'), (b'x-correlation-id', b'38b6463e-6d01-4e41-8e31-15066c708d0b'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 13:50:45: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-a9f4-400e-bcfe-c637d7bdd16f "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 13:50:45: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:50:45: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:50:45: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 13:50:45: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 13:50:45: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:50:45: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 13:50:45: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:50:45: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:50:45: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:50:45: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 11:50:45 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'6020'), (b'Connection', b'keep-alive'), (b'x-session-id', b'147bce2b-10b1-43a4-ac74-22c04148514b'), (b'x-correlation-id', b'2f34820f-8e4d-4e52-a148-3c3a9b1aa93e'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 13:50:45: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-a9f4-400e-bcfe-c637d7bdd16f/result/markdown "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 13:50:45: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:50:45: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:50:45: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 13:50:45: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 13:50:45: close.started
[DEBUG|_trace|L85] 2024-06-09 13:50:45: close.complete
[DEBUG|proactor_events|L633] 2024-06-09 13:50:45: Using proactor: IocpProactor
[DEBUG|_config|L80] 2024-06-09 13:50:45: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 13:50:45: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 13:50:46: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 13:50:46: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x00000152FA2646D0>
[DEBUG|_trace|L85] 2024-06-09 13:50:46: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000015310DA5520> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 13:50:46: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000015310D9AED0>
[DEBUG|_trace|L85] 2024-06-09 13:50:46: send_request_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:50:46: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 13:50:46: send_request_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:50:46: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:50:46: receive_response_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:50:48: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 11:50:47 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'be5fac2e-3d62-47ee-852f-3b955b8aced6'), (b'x-correlation-id', b'f27e2af7-5d1d-45bf-b8e7-e20218c53edc'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 13:50:48: HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 13:50:48: receive_response_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:50:48: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:50:48: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 13:50:48: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 13:50:48: close.started
[DEBUG|_trace|L85] 2024-06-09 13:50:48: close.complete
[DEBUG|_config|L80] 2024-06-09 13:50:49: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 13:50:49: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 13:50:49: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 13:50:49: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000015310D9AFD0>
[DEBUG|_trace|L85] 2024-06-09 13:50:49: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000015310DA63C0> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 13:50:50: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000015310D9A8D0>
[DEBUG|_trace|L85] 2024-06-09 13:50:50: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:50:50: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 13:50:50: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:50:50: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:50:50: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:50:50: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 11:50:49 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'ee2c8cae-b7d9-4eea-aa3b-770b6fa0bc02'), (b'x-correlation-id', b'23b9f73b-477e-4a6c-a8aa-3602f1c2f398'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 13:50:50: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-1eb4-448c-a01b-435eae0b4949 "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 13:50:50: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:50:50: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:50:50: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 13:50:50: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 13:50:50: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:50:50: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 13:50:50: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:50:50: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:50:50: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:50:50: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 11:50:50 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'4083'), (b'Connection', b'keep-alive'), (b'x-session-id', b'7141da36-810f-43c0-9809-e79a75f3d854'), (b'x-correlation-id', b'dd200402-39bc-4939-a796-7311838d4f82'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 13:50:50: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-1eb4-448c-a01b-435eae0b4949/result/markdown "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 13:50:50: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:50:50: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:50:50: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 13:50:50: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 13:50:50: close.started
[DEBUG|_trace|L85] 2024-06-09 13:50:50: close.complete
[DEBUG|proactor_events|L633] 2024-06-09 13:50:50: Using proactor: IocpProactor
[DEBUG|_config|L80] 2024-06-09 13:50:50: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 13:50:50: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 13:50:51: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 13:50:51: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000015310DB7C50>
[DEBUG|_trace|L85] 2024-06-09 13:50:51: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000015310DA6570> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 13:50:51: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000015310DACA50>
[DEBUG|_trace|L85] 2024-06-09 13:50:51: send_request_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:50:51: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 13:50:51: send_request_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:50:51: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:50:51: receive_response_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:50:52: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 11:50:52 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'c17fe4fc-3936-4343-8fc3-53d3afda9b2e'), (b'x-correlation-id', b'79d2b4f4-65c3-447d-aa5d-3eb3248ea7db'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 13:50:52: HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 13:50:52: receive_response_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:50:52: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:50:52: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 13:50:52: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 13:50:52: close.started
[DEBUG|_trace|L85] 2024-06-09 13:50:52: close.complete
[DEBUG|_config|L80] 2024-06-09 13:50:53: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 13:50:53: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 13:50:54: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 13:50:54: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000015310DB7F50>
[DEBUG|_trace|L85] 2024-06-09 13:50:54: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000015310DA5760> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 13:50:54: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000015324E21690>
[DEBUG|_trace|L85] 2024-06-09 13:50:54: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:50:54: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 13:50:54: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:50:54: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:50:54: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:50:54: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 11:50:54 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'e8e8345b-9601-4406-89fb-717148b9a3aa'), (b'x-correlation-id', b'f2f94361-1b4e-43ed-afe0-844620b98d84'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 13:50:54: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-21aa-492c-abd0-fb9d351c8fcc "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 13:50:54: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:50:54: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:50:54: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 13:50:54: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 13:50:54: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:50:54: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 13:50:54: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:50:54: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:50:54: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:50:56: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 11:50:56 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'4083'), (b'Connection', b'keep-alive'), (b'x-session-id', b'fe441a40-2837-431a-8cc4-5cd275e64fc0'), (b'x-correlation-id', b'70cb1077-65b8-4bd1-b891-e34776a3c3f3'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 13:50:56: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-21aa-492c-abd0-fb9d351c8fcc/result/markdown "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 13:50:56: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:50:56: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:50:56: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 13:50:56: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 13:50:56: close.started
[DEBUG|_trace|L85] 2024-06-09 13:50:56: close.complete
[DEBUG|proactor_events|L633] 2024-06-09 13:50:56: Using proactor: IocpProactor
[DEBUG|_config|L80] 2024-06-09 13:50:56: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 13:50:56: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 13:50:57: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 13:50:57: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000015324E235D0>
[DEBUG|_trace|L85] 2024-06-09 13:50:57: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000015310DA6690> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 13:50:57: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x00000152FA357810>
[DEBUG|_trace|L85] 2024-06-09 13:50:57: send_request_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:50:57: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 13:50:57: send_request_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:50:58: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:50:58: receive_response_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:51:00: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 11:51:00 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'135f1a03-64f4-4196-907d-01b851b63edc'), (b'x-correlation-id', b'795a7577-e850-4f4a-93c2-6812c8cd8aef'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 13:51:00: HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 13:51:00: receive_response_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:51:00: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:00: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 13:51:00: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:00: close.started
[DEBUG|_trace|L85] 2024-06-09 13:51:00: close.complete
[DEBUG|_config|L80] 2024-06-09 13:51:01: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 13:51:01: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 13:51:02: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 13:51:02: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000015324E22D90>
[DEBUG|_trace|L85] 2024-06-09 13:51:02: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000015310DA6600> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 13:51:02: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000015324E14150>
[DEBUG|_trace|L85] 2024-06-09 13:51:02: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:51:02: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:02: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:51:02: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:02: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:51:02: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 11:51:02 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'6d6db52e-15e9-4482-882e-5a4bff4f96b7'), (b'x-correlation-id', b'50cb3f53-48ee-4b6d-8191-dde9c5105260'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 13:51:02: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-72a0-461d-9049-e7299ab6c7cf "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 13:51:02: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:51:02: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:02: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 13:51:02: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:02: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:51:02: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:02: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:51:02: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:02: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:51:03: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 11:51:02 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'233734'), (b'Connection', b'keep-alive'), (b'x-session-id', b'22d364ec-1747-4e67-a91f-065718237c67'), (b'x-correlation-id', b'0e1932cf-589a-45dc-8af9-eb72a0317631'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 13:51:03: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-72a0-461d-9049-e7299ab6c7cf/result/markdown "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 13:51:03: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:51:03: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:03: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 13:51:03: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:03: close.started
[DEBUG|_trace|L85] 2024-06-09 13:51:03: close.complete
[DEBUG|proactor_events|L633] 2024-06-09 13:51:03: Using proactor: IocpProactor
[DEBUG|_config|L80] 2024-06-09 13:51:03: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 13:51:03: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 13:51:04: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 13:51:04: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000015324E20250>
[DEBUG|_trace|L85] 2024-06-09 13:51:04: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000015310DA75C0> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 13:51:04: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000015324E22550>
[DEBUG|_trace|L85] 2024-06-09 13:51:04: send_request_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:51:04: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:04: send_request_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:51:04: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:04: receive_response_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:51:06: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 11:51:05 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'66bb6169-faf6-455e-b248-18bec4847864'), (b'x-correlation-id', b'62893820-a256-45cb-80f4-4357c2720f07'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 13:51:06: HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 13:51:06: receive_response_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:51:06: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:06: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 13:51:06: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:06: close.started
[DEBUG|_trace|L85] 2024-06-09 13:51:06: close.complete
[DEBUG|_config|L80] 2024-06-09 13:51:07: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 13:51:07: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 13:51:07: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 13:51:07: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000015324E23E10>
[DEBUG|_trace|L85] 2024-06-09 13:51:07: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000015310DA6690> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 13:51:07: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x00000152FB1E5F10>
[DEBUG|_trace|L85] 2024-06-09 13:51:07: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:51:07: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:07: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:51:07: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:07: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:51:08: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 11:51:07 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'a0ddaa66-2654-4052-84c7-f53d42221536'), (b'x-correlation-id', b'6bd6b1d7-3e1b-4f6d-9c92-ce442f9af612'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 13:51:08: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-8d62-4295-ae6d-5eaa1c0e424e "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 13:51:08: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:51:08: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:08: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 13:51:08: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:08: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:51:08: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:08: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:51:08: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:08: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:51:08: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 11:51:08 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'8463'), (b'Connection', b'keep-alive'), (b'x-session-id', b'a04d85bd-87f3-43bd-a103-1875716a80c4'), (b'x-correlation-id', b'82c4893e-2708-4be2-8286-975a1332df36'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 13:51:08: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-8d62-4295-ae6d-5eaa1c0e424e/result/markdown "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 13:51:08: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:51:08: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:08: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 13:51:08: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:08: close.started
[DEBUG|_trace|L85] 2024-06-09 13:51:08: close.complete
[DEBUG|proactor_events|L633] 2024-06-09 13:51:08: Using proactor: IocpProactor
[DEBUG|_config|L80] 2024-06-09 13:51:08: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 13:51:08: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 13:51:09: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 13:51:09: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000015310DADA90>
[DEBUG|_trace|L85] 2024-06-09 13:51:09: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000015310DA7650> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 13:51:09: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000015324E22110>
[DEBUG|_trace|L85] 2024-06-09 13:51:09: send_request_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:51:09: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:09: send_request_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:51:10: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:10: receive_response_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:51:11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 11:51:10 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'1a5286e2-9b6e-4a9a-b473-53ebdea9f76a'), (b'x-correlation-id', b'eb78fd48-0588-4a97-9dd9-2fd8d6a29b9c'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 13:51:11: HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 13:51:11: receive_response_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:51:11: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:11: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 13:51:11: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:11: close.started
[DEBUG|_trace|L85] 2024-06-09 13:51:11: close.complete
[DEBUG|_config|L80] 2024-06-09 13:51:12: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 13:51:12: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 13:51:12: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 13:51:12: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000015310D9A810>
[DEBUG|_trace|L85] 2024-06-09 13:51:12: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000015310DA67B0> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 13:51:13: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000015310DB6990>
[DEBUG|_trace|L85] 2024-06-09 13:51:13: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:51:13: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:13: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:51:13: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:13: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:51:13: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 11:51:12 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'8a84c3ec-27c5-414e-86db-f7e586bccbd5'), (b'x-correlation-id', b'8f1dfb65-0d7a-466a-9f33-c7985e543ce3'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 13:51:13: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-5743-4572-94e5-68a2a4600575 "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 13:51:13: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:51:13: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:13: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 13:51:13: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:13: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:51:13: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:13: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:51:13: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:13: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:51:13: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 11:51:13 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'12669'), (b'Connection', b'keep-alive'), (b'x-session-id', b'a9c5c4d7-58c5-45f3-b1ce-3f61afdd9f45'), (b'x-correlation-id', b'b9b7898a-ac10-4a40-81d3-af7771aa69f3'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 13:51:13: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-5743-4572-94e5-68a2a4600575/result/markdown "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 13:51:13: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:51:13: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:13: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 13:51:13: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:13: close.started
[DEBUG|_trace|L85] 2024-06-09 13:51:13: close.complete
[DEBUG|proactor_events|L633] 2024-06-09 13:51:13: Using proactor: IocpProactor
[DEBUG|_config|L80] 2024-06-09 13:51:13: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 13:51:13: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 13:51:14: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 13:51:14: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000015310DACB50>
[DEBUG|_trace|L85] 2024-06-09 13:51:14: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000015310DA7DA0> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 13:51:14: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x00000152FD4F3350>
[DEBUG|_trace|L85] 2024-06-09 13:51:14: send_request_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:51:14: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:14: send_request_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:51:14: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:14: receive_response_headers.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:51:16: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 11:51:15 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'3a0684ed-01d4-43e1-a910-55b673ff52f5'), (b'x-correlation-id', b'7e745790-e202-4a00-be9d-f533f9481b51'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 13:51:16: HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 13:51:16: receive_response_body.started request=<Request [b'POST']>
[DEBUG|_trace|L85] 2024-06-09 13:51:16: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:16: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 13:51:16: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:16: close.started
[DEBUG|_trace|L85] 2024-06-09 13:51:16: close.complete
[DEBUG|_config|L80] 2024-06-09 13:51:17: load_ssl_context verify=True cert=None trust_env=True http2=False
[DEBUG|_config|L146] 2024-06-09 13:51:17: load_verify_locations cafile='C:\\Users\\Jorge\\Desktop\\MASTER_IA\\TFM\\proyecto\\env\\Lib\\site-packages\\certifi\\cacert.pem'
[DEBUG|_trace|L85] 2024-06-09 13:51:18: connect_tcp.started host='api.cloud.llamaindex.ai' port=443 local_address=None timeout=2000 socket_options=None
[DEBUG|_trace|L85] 2024-06-09 13:51:18: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000015324E17450>
[DEBUG|_trace|L85] 2024-06-09 13:51:18: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000015310DA7E30> server_hostname='api.cloud.llamaindex.ai' timeout=2000
[DEBUG|_trace|L85] 2024-06-09 13:51:18: start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000015324E15CD0>
[DEBUG|_trace|L85] 2024-06-09 13:51:18: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:51:18: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:18: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:51:18: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:18: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:51:18: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 11:51:18 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'64'), (b'Connection', b'keep-alive'), (b'x-session-id', b'32166540-05fe-450f-8258-ef9f8d26c1b5'), (b'x-correlation-id', b'a3497ad7-965d-49dc-b326-da50cf3117f4'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
[INFO|_client|L1773] 2024-06-09 13:51:18: HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cac11eca-319a-4afb-b90c-25768c74cb3b "HTTP/1.1 200 OK"
[DEBUG|_trace|L85] 2024-06-09 13:51:18: receive_response_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:51:18: receive_response_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:18: response_closed.started
[DEBUG|_trace|L85] 2024-06-09 13:51:18: response_closed.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:18: send_request_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:51:18: send_request_headers.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:18: send_request_body.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:51:18: send_request_body.complete
[DEBUG|_trace|L85] 2024-06-09 13:51:18: receive_response_headers.started request=<Request [b'GET']>
[DEBUG|_trace|L85] 2024-06-09 13:51:18: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 09 Jun 2024 11:51:18 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'1341'), (b'Connection', b'keep-alive'), (b'x-session-id', b'98a2c41f-281c-4bc4-9545-f85fd5452a11'), (b'x-correlation-id', b'015a8357-5b35-4428-8e0f-6db5c13e19a3'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains')])
